{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVbhUge1s9hnLitdNdMfAV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhammadsoliyev/CreditScoring/blob/main/scoring_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xBRnpNoVUzAR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "# %matplotlib notebook\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "# plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_style(\"whitegrid\")\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.warn(\"this will not show\")\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All necessary libraries\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.saving import save_model"
      ],
      "metadata": {
        "id": "pv7Sx-hVU2dL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv', dtype={'Column26': str})\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "T2Y8il3qU44_",
        "outputId": "0b7e483f-fe7b-4802-97fd-606f2268c23c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID Customer_ID     Month           Name  Age          SSN Occupation  \\\n",
              "0  0x1602   CUS_0xd40   January  Aaron Maashoh   23  821-00-0265  Scientist   \n",
              "1  0x1603   CUS_0xd40  February  Aaron Maashoh   23  821-00-0265  Scientist   \n",
              "2  0x1604   CUS_0xd40     March  Aaron Maashoh    5  821-00-0265  Scientist   \n",
              "3  0x1605   CUS_0xd40     April  Aaron Maashoh   23  821-00-0265  Scientist   \n",
              "4  0x1606   CUS_0xd40       May  Aaron Maashoh   23  821-00-0265  Scientist   \n",
              "\n",
              "  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  ...  Credit_Mix  \\\n",
              "0      19114.12               1824.843                  3  ...        Good   \n",
              "1      19114.12               1824.843                  3  ...        Good   \n",
              "2      19114.12               1824.843                  3  ...        Good   \n",
              "3      19114.12               1824.843                  3  ...        Good   \n",
              "4      19114.12               1824.843                  3  ...        Good   \n",
              "\n",
              "   Outstanding_Debt  Credit_Utilization_Ratio Payment_of_Min_Amount  \\\n",
              "0            809.98                    26.823                    No   \n",
              "1            809.98                    31.945                    No   \n",
              "2            809.98                    28.609                    No   \n",
              "3            809.98                    31.378                    No   \n",
              "4            809.98                    24.797                    No   \n",
              "\n",
              "   Total_EMI_per_month  Amount_invested_monthly  \\\n",
              "0               49.575                  118.280   \n",
              "1               49.575                  118.280   \n",
              "2               49.575                  118.280   \n",
              "3               49.575                  118.280   \n",
              "4               49.575                  118.280   \n",
              "\n",
              "                  Payment_Behaviour  Monthly_Balance Credit_Score  \\\n",
              "0   High_spent_Small_value_payments          312.494         Good   \n",
              "1    Low_spent_Large_value_payments          284.629         Good   \n",
              "2   Low_spent_Medium_value_payments          331.210         Good   \n",
              "3    Low_spent_Small_value_payments          223.451         Good   \n",
              "4  High_spent_Medium_value_payments          341.489         Good   \n",
              "\n",
              "  Credit_History_Age_Months  \n",
              "0                   265.000  \n",
              "1                   265.000  \n",
              "2                   267.000  \n",
              "3                   268.000  \n",
              "4                   269.000  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56878dff-4e4c-4812-ba34-7793141bafe4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Customer_ID</th>\n",
              "      <th>Month</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SSN</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Inhand_Salary</th>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <th>...</th>\n",
              "      <th>Credit_Mix</th>\n",
              "      <th>Outstanding_Debt</th>\n",
              "      <th>Credit_Utilization_Ratio</th>\n",
              "      <th>Payment_of_Min_Amount</th>\n",
              "      <th>Total_EMI_per_month</th>\n",
              "      <th>Amount_invested_monthly</th>\n",
              "      <th>Payment_Behaviour</th>\n",
              "      <th>Monthly_Balance</th>\n",
              "      <th>Credit_Score</th>\n",
              "      <th>Credit_History_Age_Months</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x1602</td>\n",
              "      <td>CUS_0xd40</td>\n",
              "      <td>January</td>\n",
              "      <td>Aaron Maashoh</td>\n",
              "      <td>23</td>\n",
              "      <td>821-00-0265</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>26.823</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Small_value_payments</td>\n",
              "      <td>312.494</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x1603</td>\n",
              "      <td>CUS_0xd40</td>\n",
              "      <td>February</td>\n",
              "      <td>Aaron Maashoh</td>\n",
              "      <td>23</td>\n",
              "      <td>821-00-0265</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>31.945</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Large_value_payments</td>\n",
              "      <td>284.629</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x1604</td>\n",
              "      <td>CUS_0xd40</td>\n",
              "      <td>March</td>\n",
              "      <td>Aaron Maashoh</td>\n",
              "      <td>5</td>\n",
              "      <td>821-00-0265</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>28.609</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Medium_value_payments</td>\n",
              "      <td>331.210</td>\n",
              "      <td>Good</td>\n",
              "      <td>267.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x1605</td>\n",
              "      <td>CUS_0xd40</td>\n",
              "      <td>April</td>\n",
              "      <td>Aaron Maashoh</td>\n",
              "      <td>23</td>\n",
              "      <td>821-00-0265</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>31.378</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Small_value_payments</td>\n",
              "      <td>223.451</td>\n",
              "      <td>Good</td>\n",
              "      <td>268.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x1606</td>\n",
              "      <td>CUS_0xd40</td>\n",
              "      <td>May</td>\n",
              "      <td>Aaron Maashoh</td>\n",
              "      <td>23</td>\n",
              "      <td>821-00-0265</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.12</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>24.797</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Medium_value_payments</td>\n",
              "      <td>341.489</td>\n",
              "      <td>Good</td>\n",
              "      <td>269.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56878dff-4e4c-4812-ba34-7793141bafe4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56878dff-4e4c-4812-ba34-7793141bafe4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56878dff-4e4c-4812-ba34-7793141bafe4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5fdb5bd1-1e98-4bd8-a6a5-7c17637e9359\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fdb5bd1-1e98-4bd8-a6a5-7c17637e9359')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5fdb5bd1-1e98-4bd8-a6a5-7c17637e9359 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnS0-t90c1TZ",
        "outputId": "94ba2a21-6bd6-4297-8066-858be27da704"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38092, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = train\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Bk_lWVdAok",
        "outputId": "32beabae-240d-4824-8038-c522b1b9cd89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38092 entries, 0 to 38091\n",
            "Data columns (total 28 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   ID                         38092 non-null  object \n",
            " 1   Customer_ID                38092 non-null  object \n",
            " 2   Month                      38092 non-null  object \n",
            " 3   Name                       38092 non-null  object \n",
            " 4   Age                        38092 non-null  int64  \n",
            " 5   SSN                        38092 non-null  object \n",
            " 6   Occupation                 38092 non-null  object \n",
            " 7   Annual_Income              38092 non-null  object \n",
            " 8   Monthly_Inhand_Salary      38092 non-null  float64\n",
            " 9   Num_Bank_Accounts          38092 non-null  int64  \n",
            " 10  Num_Credit_Card            38092 non-null  int64  \n",
            " 11  Interest_Rate              38092 non-null  float64\n",
            " 12  Num_of_Loan                38092 non-null  int64  \n",
            " 13  Type_of_Loan               38092 non-null  object \n",
            " 14  Delay_from_due_date        38092 non-null  int64  \n",
            " 15  Num_of_Delayed_Payment     38092 non-null  int64  \n",
            " 16  Changed_Credit_Limit       38092 non-null  float64\n",
            " 17  Num_Credit_Inquiries       38092 non-null  float64\n",
            " 18  Credit_Mix                 38092 non-null  object \n",
            " 19  Outstanding_Debt           38092 non-null  object \n",
            " 20  Credit_Utilization_Ratio   38092 non-null  float64\n",
            " 21  Payment_of_Min_Amount      38091 non-null  object \n",
            " 22  Total_EMI_per_month        38091 non-null  float64\n",
            " 23  Amount_invested_monthly    38091 non-null  float64\n",
            " 24  Payment_Behaviour          38091 non-null  object \n",
            " 25  Monthly_Balance            38091 non-null  float64\n",
            " 26  Credit_Score               38091 non-null  object \n",
            " 27  Credit_History_Age_Months  38091 non-null  float64\n",
            "dtypes: float64(9), int64(6), object(13)\n",
            "memory usage: 8.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oxiridagi _ ni olib tashlash uchun\n",
        "def remove_trailing_dash(value):\n",
        "    if isinstance(value, str) and value.endswith('_'):\n",
        "        return value[:-1]  # Oxirgi belgini olib tashlang (chiziq)\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "\n",
        "df['Annual_Income'] = df['Annual_Income'].apply(remove_trailing_dash)"
      ],
      "metadata": {
        "id": "VwoVBAZxdF8E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Annual_Income'] = df['Annual_Income'].astype(float)"
      ],
      "metadata": {
        "id": "Bb4pi5sigKKI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Annual_Income'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsK7LclMgUwJ",
        "outputId": "cb72ac64-1a08-4a4b-ff28-4b1bd9c4fa6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.9114120e+04, 3.4847840e+04, 1.4316264e+05, ..., 2.3435862e+07,\n",
              "       2.4813210e+04, 8.3669520e+04])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['ID','Customer_ID', 'Month', 'Name','SSN', 'Type_of_Loan'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "dBMTkWI-gW9h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "4v4l9DxBgzVO",
        "outputId": "6ec0cd77-89d2-4705-ed7a-ba9513d06a91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
              "0   23  Scientist      19114.120               1824.843                  3   \n",
              "1   23  Scientist      19114.120               1824.843                  3   \n",
              "2    5  Scientist      19114.120               1824.843                  3   \n",
              "3   23  Scientist      19114.120               1824.843                  3   \n",
              "4   23  Scientist      19114.120               1824.843                  3   \n",
              "\n",
              "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
              "0                4          3.000            4                    3   \n",
              "1                4          3.000            4                   -1   \n",
              "2                4          3.000            4                    3   \n",
              "3                4          3.000            4                    5   \n",
              "4                4          3.000            4                    6   \n",
              "\n",
              "   Num_of_Delayed_Payment  ...  Credit_Mix  Outstanding_Debt  \\\n",
              "0                       7  ...        Good            809.98   \n",
              "1                       0  ...        Good            809.98   \n",
              "2                       7  ...        Good            809.98   \n",
              "3                       4  ...        Good            809.98   \n",
              "4                       0  ...        Good            809.98   \n",
              "\n",
              "  Credit_Utilization_Ratio Payment_of_Min_Amount  Total_EMI_per_month  \\\n",
              "0                   26.823                    No               49.575   \n",
              "1                   31.945                    No               49.575   \n",
              "2                   28.609                    No               49.575   \n",
              "3                   31.378                    No               49.575   \n",
              "4                   24.797                    No               49.575   \n",
              "\n",
              "  Amount_invested_monthly                 Payment_Behaviour  Monthly_Balance  \\\n",
              "0                 118.280   High_spent_Small_value_payments          312.494   \n",
              "1                 118.280    Low_spent_Large_value_payments          284.629   \n",
              "2                 118.280   Low_spent_Medium_value_payments          331.210   \n",
              "3                 118.280    Low_spent_Small_value_payments          223.451   \n",
              "4                 118.280  High_spent_Medium_value_payments          341.489   \n",
              "\n",
              "  Credit_Score  Credit_History_Age_Months  \n",
              "0         Good                    265.000  \n",
              "1         Good                    265.000  \n",
              "2         Good                    267.000  \n",
              "3         Good                    268.000  \n",
              "4         Good                    269.000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f01b6bfd-ba47-45e0-9ce8-92408e12acbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Inhand_Salary</th>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <th>Num_Credit_Card</th>\n",
              "      <th>Interest_Rate</th>\n",
              "      <th>Num_of_Loan</th>\n",
              "      <th>Delay_from_due_date</th>\n",
              "      <th>Num_of_Delayed_Payment</th>\n",
              "      <th>...</th>\n",
              "      <th>Credit_Mix</th>\n",
              "      <th>Outstanding_Debt</th>\n",
              "      <th>Credit_Utilization_Ratio</th>\n",
              "      <th>Payment_of_Min_Amount</th>\n",
              "      <th>Total_EMI_per_month</th>\n",
              "      <th>Amount_invested_monthly</th>\n",
              "      <th>Payment_Behaviour</th>\n",
              "      <th>Monthly_Balance</th>\n",
              "      <th>Credit_Score</th>\n",
              "      <th>Credit_History_Age_Months</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>26.823</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Small_value_payments</td>\n",
              "      <td>312.494</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>31.945</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Large_value_payments</td>\n",
              "      <td>284.629</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>28.609</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Medium_value_payments</td>\n",
              "      <td>331.210</td>\n",
              "      <td>Good</td>\n",
              "      <td>267.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>31.378</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Small_value_payments</td>\n",
              "      <td>223.451</td>\n",
              "      <td>Good</td>\n",
              "      <td>268.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.98</td>\n",
              "      <td>24.797</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Medium_value_payments</td>\n",
              "      <td>341.489</td>\n",
              "      <td>Good</td>\n",
              "      <td>269.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f01b6bfd-ba47-45e0-9ce8-92408e12acbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f01b6bfd-ba47-45e0-9ce8-92408e12acbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f01b6bfd-ba47-45e0-9ce8-92408e12acbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f01ce0f7-fe0a-460a-b587-d241c3761f85\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f01ce0f7-fe0a-460a-b587-d241c3761f85')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f01ce0f7-fe0a-460a-b587-d241c3761f85 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_convert = ['Num_of_Delayed_Payment', 'Outstanding_Debt', 'Amount_invested_monthly','Num_of_Loan']\n",
        "for col in columns_to_convert:\n",
        "    df[col] = df[col].astype(str).str.replace('_', '').astype(float)"
      ],
      "metadata": {
        "id": "gLUoUUgzg4Of"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiSb9Aw-hHM_",
        "outputId": "4288baf5-f5f3-460b-b1af-a69942b0c1ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                            int64\n",
              "Occupation                    object\n",
              "Annual_Income                float64\n",
              "Monthly_Inhand_Salary        float64\n",
              "Num_Bank_Accounts              int64\n",
              "Num_Credit_Card                int64\n",
              "Interest_Rate                float64\n",
              "Num_of_Loan                  float64\n",
              "Delay_from_due_date            int64\n",
              "Num_of_Delayed_Payment       float64\n",
              "Changed_Credit_Limit         float64\n",
              "Num_Credit_Inquiries         float64\n",
              "Credit_Mix                    object\n",
              "Outstanding_Debt             float64\n",
              "Credit_Utilization_Ratio     float64\n",
              "Payment_of_Min_Amount         object\n",
              "Total_EMI_per_month          float64\n",
              "Amount_invested_monthly      float64\n",
              "Payment_Behaviour             object\n",
              "Monthly_Balance              float64\n",
              "Credit_Score                  object\n",
              "Credit_History_Age_Months    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "3Rma1PO9l7JT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['Payment_Behaviour'] != '!@9#%8']"
      ],
      "metadata": {
        "id": "t2vsDRvXpEj5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and read clean data\n",
        "df.to_csv(\"train_cleaned.csv\", index=False)"
      ],
      "metadata": {
        "id": "6lTCER6_hgbH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train_cleaned.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "fLYZYDl7jcz0",
        "outputId": "0ce74204-ff7c-4449-fa28-bb9d7f6aa675"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age Occupation  Annual_Income  Monthly_Inhand_Salary  Num_Bank_Accounts  \\\n",
              "0   23  Scientist      19114.120               1824.843                  3   \n",
              "1   23  Scientist      19114.120               1824.843                  3   \n",
              "2    5  Scientist      19114.120               1824.843                  3   \n",
              "3   23  Scientist      19114.120               1824.843                  3   \n",
              "4   23  Scientist      19114.120               1824.843                  3   \n",
              "\n",
              "   Num_Credit_Card  Interest_Rate  Num_of_Loan  Delay_from_due_date  \\\n",
              "0                4          3.000        4.000                    3   \n",
              "1                4          3.000        4.000                   -1   \n",
              "2                4          3.000        4.000                    3   \n",
              "3                4          3.000        4.000                    5   \n",
              "4                4          3.000        4.000                    6   \n",
              "\n",
              "   Num_of_Delayed_Payment  ...  Credit_Mix  Outstanding_Debt  \\\n",
              "0                   7.000  ...        Good           809.980   \n",
              "1                   0.000  ...        Good           809.980   \n",
              "2                   7.000  ...        Good           809.980   \n",
              "3                   4.000  ...        Good           809.980   \n",
              "4                   0.000  ...        Good           809.980   \n",
              "\n",
              "  Credit_Utilization_Ratio  Payment_of_Min_Amount  Total_EMI_per_month  \\\n",
              "0                   26.823                     No               49.575   \n",
              "1                   31.945                     No               49.575   \n",
              "2                   28.609                     No               49.575   \n",
              "3                   31.378                     No               49.575   \n",
              "4                   24.797                     No               49.575   \n",
              "\n",
              "  Amount_invested_monthly                 Payment_Behaviour  Monthly_Balance  \\\n",
              "0                 118.280   High_spent_Small_value_payments          312.494   \n",
              "1                 118.280    Low_spent_Large_value_payments          284.629   \n",
              "2                 118.280   Low_spent_Medium_value_payments          331.210   \n",
              "3                 118.280    Low_spent_Small_value_payments          223.451   \n",
              "4                 118.280  High_spent_Medium_value_payments          341.489   \n",
              "\n",
              "  Credit_Score  Credit_History_Age_Months  \n",
              "0         Good                    265.000  \n",
              "1         Good                    265.000  \n",
              "2         Good                    267.000  \n",
              "3         Good                    268.000  \n",
              "4         Good                    269.000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59f70c3e-92da-4fae-a283-788a38490f64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Inhand_Salary</th>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <th>Num_Credit_Card</th>\n",
              "      <th>Interest_Rate</th>\n",
              "      <th>Num_of_Loan</th>\n",
              "      <th>Delay_from_due_date</th>\n",
              "      <th>Num_of_Delayed_Payment</th>\n",
              "      <th>...</th>\n",
              "      <th>Credit_Mix</th>\n",
              "      <th>Outstanding_Debt</th>\n",
              "      <th>Credit_Utilization_Ratio</th>\n",
              "      <th>Payment_of_Min_Amount</th>\n",
              "      <th>Total_EMI_per_month</th>\n",
              "      <th>Amount_invested_monthly</th>\n",
              "      <th>Payment_Behaviour</th>\n",
              "      <th>Monthly_Balance</th>\n",
              "      <th>Credit_Score</th>\n",
              "      <th>Credit_History_Age_Months</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3</td>\n",
              "      <td>7.000</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.980</td>\n",
              "      <td>26.823</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Small_value_payments</td>\n",
              "      <td>312.494</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.980</td>\n",
              "      <td>31.945</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Large_value_payments</td>\n",
              "      <td>284.629</td>\n",
              "      <td>Good</td>\n",
              "      <td>265.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>3</td>\n",
              "      <td>7.000</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.980</td>\n",
              "      <td>28.609</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Medium_value_payments</td>\n",
              "      <td>331.210</td>\n",
              "      <td>Good</td>\n",
              "      <td>267.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>5</td>\n",
              "      <td>4.000</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.980</td>\n",
              "      <td>31.378</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>Low_spent_Small_value_payments</td>\n",
              "      <td>223.451</td>\n",
              "      <td>Good</td>\n",
              "      <td>268.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>Scientist</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>Good</td>\n",
              "      <td>809.980</td>\n",
              "      <td>24.797</td>\n",
              "      <td>No</td>\n",
              "      <td>49.575</td>\n",
              "      <td>118.280</td>\n",
              "      <td>High_spent_Medium_value_payments</td>\n",
              "      <td>341.489</td>\n",
              "      <td>Good</td>\n",
              "      <td>269.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59f70c3e-92da-4fae-a283-788a38490f64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59f70c3e-92da-4fae-a283-788a38490f64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59f70c3e-92da-4fae-a283-788a38490f64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8538f94c-64ab-4065-9648-955a58168865\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8538f94c-64ab-4065-9648-955a58168865')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8538f94c-64ab-4065-9648-955a58168865 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHWK3RvCkg7Y",
        "outputId": "64b4ae79-2de1-424e-dd0d-322ed3eb20fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                          0\n",
              "Occupation                   0\n",
              "Annual_Income                0\n",
              "Monthly_Inhand_Salary        0\n",
              "Num_Bank_Accounts            0\n",
              "Num_Credit_Card              0\n",
              "Interest_Rate                0\n",
              "Num_of_Loan                  0\n",
              "Delay_from_due_date          0\n",
              "Num_of_Delayed_Payment       0\n",
              "Changed_Credit_Limit         0\n",
              "Num_Credit_Inquiries         0\n",
              "Credit_Mix                   0\n",
              "Outstanding_Debt             0\n",
              "Credit_Utilization_Ratio     0\n",
              "Payment_of_Min_Amount        0\n",
              "Total_EMI_per_month          0\n",
              "Amount_invested_monthly      0\n",
              "Payment_Behaviour            0\n",
              "Monthly_Balance              0\n",
              "Credit_Score                 0\n",
              "Credit_History_Age_Months    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoding for output column\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "df[\"Credit_Score\"] = LabelEncoder().fit_transform(df[\"Credit_Score\"])\n",
        "df[\"Credit_Score\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu61rno3klm1",
        "outputId": "13c2bc2e-f2fe-48f9-b9b7-b6ef6f6175a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "35228    2\n",
              "35229    2\n",
              "35230    2\n",
              "35231    2\n",
              "35232    2\n",
              "Name: Credit_Score, Length: 35233, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Credit_Score\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkPH1fJrmMoa",
        "outputId": "0abc5be6-f2e9-45a5-f759-dc7c722450df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Credit_Score\n",
              "2    18673\n",
              "1    10290\n",
              "0     6270\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation of target variable with features after numerical transformation\n",
        "\n",
        "\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "correlation_series = numerical_df.corr()['Credit_Score'][:-1].sort_values()\n",
        "correlation_series.plot.barh();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "5IrxBLeFmiYE",
        "outputId": "aef57c2f-6853-4bcb-a4fc-850089d39228"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding for categorical columns\n",
        "# select columns of type 'object'\n",
        "df.select_dtypes(include=['object']).columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyh2MeG2oDJF",
        "outputId": "1edfa805-4ea0-4a40-c3b1-2cb6ba24bc9c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Occupation', 'Credit_Mix', 'Payment_of_Min_Amount',\n",
              "       'Payment_Behaviour'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payment_behaviour_categories = ['Low_spent_Small_value_payments',\n",
        "                                'Low_spent_Medium_value_payments',\n",
        "                                'Low_spent_Large_value_payments',\n",
        "                                'High_spent_Small_value_payments',\n",
        "                                'High_spent_Medium_value_payments',\n",
        "                                'High_spent_Large_value_payments']\n",
        "\n",
        "payment_behaviour_encoder = OrdinalEncoder(categories=[payment_behaviour_categories])\n",
        "\n",
        "df['Payment_Behaviour'] = payment_behaviour_encoder.fit_transform(df[['Payment_Behaviour']])"
      ],
      "metadata": {
        "id": "54NjS8qOoPAB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = OrdinalEncoder()\n",
        "df['Credit_Mix'] = label_encoder.fit_transform(df[['Credit_Mix']])"
      ],
      "metadata": {
        "id": "01KpF6UIoRgh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['Payment_of_Min_Amount'] = label_encoder.fit_transform(df['Payment_of_Min_Amount'])"
      ],
      "metadata": {
        "id": "e2cC2jIfpJdJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['Occupation'] = label_encoder.fit_transform(df['Occupation'])"
      ],
      "metadata": {
        "id": "Npzpyu63pLtj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcnduzpZpNmj",
        "outputId": "ea1ed527-fe78-4385-928f-bda6d34b1a10"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35233, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "UXfjr7lApPZN",
        "outputId": "2f0c685c-e7df-4f96-84e6-ce99ec14b2db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  0         1         2         3         4\n",
              "Age                          23.000    23.000     5.000    23.000    23.000\n",
              "Occupation                   12.000    12.000    12.000    12.000    12.000\n",
              "Annual_Income             19114.120 19114.120 19114.120 19114.120 19114.120\n",
              "Monthly_Inhand_Salary      1824.843  1824.843  1824.843  1824.843  1824.843\n",
              "Num_Bank_Accounts             3.000     3.000     3.000     3.000     3.000\n",
              "Num_Credit_Card               4.000     4.000     4.000     4.000     4.000\n",
              "Interest_Rate                 3.000     3.000     3.000     3.000     3.000\n",
              "Num_of_Loan                   4.000     4.000     4.000     4.000     4.000\n",
              "Delay_from_due_date           3.000    -1.000     3.000     5.000     6.000\n",
              "Num_of_Delayed_Payment        7.000     0.000     7.000     4.000     0.000\n",
              "Changed_Credit_Limit         11.270    11.270    10.389     6.270    11.270\n",
              "Num_Credit_Inquiries          4.000     4.000     4.000     4.000     4.000\n",
              "Credit_Mix                    1.000     1.000     1.000     1.000     1.000\n",
              "Outstanding_Debt            809.980   809.980   809.980   809.980   809.980\n",
              "Credit_Utilization_Ratio     26.823    31.945    28.609    31.378    24.797\n",
              "Payment_of_Min_Amount         1.000     1.000     1.000     1.000     1.000\n",
              "Total_EMI_per_month          49.575    49.575    49.575    49.575    49.575\n",
              "Amount_invested_monthly     118.280   118.280   118.280   118.280   118.280\n",
              "Payment_Behaviour             3.000     2.000     1.000     0.000     4.000\n",
              "Monthly_Balance             312.494   284.629   331.210   223.451   341.489\n",
              "Credit_Score                  0.000     0.000     0.000     0.000     0.000\n",
              "Credit_History_Age_Months   265.000   265.000   267.000   268.000   269.000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aea5cb23-e507-44c4-b46b-aea6c4cf2d45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>23.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>23.000</td>\n",
              "      <td>23.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Occupation</th>\n",
              "      <td>12.000</td>\n",
              "      <td>12.000</td>\n",
              "      <td>12.000</td>\n",
              "      <td>12.000</td>\n",
              "      <td>12.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual_Income</th>\n",
              "      <td>19114.120</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>19114.120</td>\n",
              "      <td>19114.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Monthly_Inhand_Salary</th>\n",
              "      <td>1824.843</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>1824.843</td>\n",
              "      <td>1824.843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_Bank_Accounts</th>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_Credit_Card</th>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Interest_Rate</th>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_of_Loan</th>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delay_from_due_date</th>\n",
              "      <td>3.000</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>6.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_of_Delayed_Payment</th>\n",
              "      <td>7.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>7.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Changed_Credit_Limit</th>\n",
              "      <td>11.270</td>\n",
              "      <td>11.270</td>\n",
              "      <td>10.389</td>\n",
              "      <td>6.270</td>\n",
              "      <td>11.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_Credit_Inquiries</th>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "      <td>4.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit_Mix</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outstanding_Debt</th>\n",
              "      <td>809.980</td>\n",
              "      <td>809.980</td>\n",
              "      <td>809.980</td>\n",
              "      <td>809.980</td>\n",
              "      <td>809.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit_Utilization_Ratio</th>\n",
              "      <td>26.823</td>\n",
              "      <td>31.945</td>\n",
              "      <td>28.609</td>\n",
              "      <td>31.378</td>\n",
              "      <td>24.797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payment_of_Min_Amount</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_EMI_per_month</th>\n",
              "      <td>49.575</td>\n",
              "      <td>49.575</td>\n",
              "      <td>49.575</td>\n",
              "      <td>49.575</td>\n",
              "      <td>49.575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount_invested_monthly</th>\n",
              "      <td>118.280</td>\n",
              "      <td>118.280</td>\n",
              "      <td>118.280</td>\n",
              "      <td>118.280</td>\n",
              "      <td>118.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Payment_Behaviour</th>\n",
              "      <td>3.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Monthly_Balance</th>\n",
              "      <td>312.494</td>\n",
              "      <td>284.629</td>\n",
              "      <td>331.210</td>\n",
              "      <td>223.451</td>\n",
              "      <td>341.489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit_Score</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Credit_History_Age_Months</th>\n",
              "      <td>265.000</td>\n",
              "      <td>265.000</td>\n",
              "      <td>267.000</td>\n",
              "      <td>268.000</td>\n",
              "      <td>269.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aea5cb23-e507-44c4-b46b-aea6c4cf2d45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aea5cb23-e507-44c4-b46b-aea6c4cf2d45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aea5cb23-e507-44c4-b46b-aea6c4cf2d45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25d3a629-68f5-463e-bc5d-cbff7f723609\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25d3a629-68f5-463e-bc5d-cbff7f723609')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25d3a629-68f5-463e-bc5d-cbff7f723609 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate properties and target variable\n",
        "\n",
        "X = df.drop(\"Credit_Score\", axis=1)\n",
        "y = df.Credit_Score"
      ],
      "metadata": {
        "id": "qXnexzoypa0a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwOnvLYpeod",
        "outputId": "d258dd44-1ee7-48cd-c8e2-625f1979b477"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Credit_Score\n",
              "2   0.530\n",
              "1   0.292\n",
              "0   0.178\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Synthetic Minority Oversampling Technique\n",
        "\n",
        "smote = SMOTE()\n",
        "X, y = smote.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "7dPM9qoMpgjO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcLn3YtrpmEf",
        "outputId": "e5046e3b-0029-4a1b-8de1-b83f33799f1b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Credit_Score\n",
              "0    18673\n",
              "2    18673\n",
              "1    18673\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15,\n",
        "                                                    stratify=y, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "Ynk-wIPlpvZp"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEUL31Cdp0d6",
        "outputId": "3e0fd6ef-8c9f-4089-c4f4-925f362af4ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (47616, 21) (47616,)\n",
            "Testing set shape: (8403, 21) (8403,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Credit_Score\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXNs0MKPp2dF",
        "outputId": "76f87144-1bb5-4239-84f2-1f4aca9d2fca"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Credit_Score\n",
              "2    18673\n",
              "1    10290\n",
              "0     6270\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "xPjmTdxTp8IP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
        "    y_train_pred_probabilities = model.predict(X_train)\n",
        "    y_train_pred = y_train_pred_probabilities.argmax(axis=1)\n",
        "    y_pred_probabilities = model.predict(X_test)\n",
        "    y_pred = y_pred_probabilities.argmax(axis=1)\n",
        "\n",
        "    print(\"Test Set:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nTrain Set:\")\n",
        "    print(confusion_matrix(y_train, y_train_pred))\n",
        "    print(classification_report(y_train, y_train_pred))"
      ],
      "metadata": {
        "id": "jXxC6T9IqFFJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN Model\n",
        "model = Sequential([\n",
        "    Dense(512, input_dim=X_train.shape[1], activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                               patience=120,\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          validation_data=(X_test, y_test),\n",
        "          validation_split=0.1,\n",
        "          batch_size=512,\n",
        "          epochs=900,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_hFkcNtqGyo",
        "outputId": "a46ad2e8-8c87-43d9-b851-47b85f6904b8",
        "collapsed": true
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/900\n",
            "93/93 [==============================] - 8s 51ms/step - loss: 0.8324 - accuracy: 0.6471 - val_loss: 0.7411 - val_accuracy: 0.7068\n",
            "Epoch 2/900\n",
            "93/93 [==============================] - 5s 50ms/step - loss: 0.7398 - accuracy: 0.7091 - val_loss: 0.7141 - val_accuracy: 0.7150\n",
            "Epoch 3/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.7219 - accuracy: 0.7155 - val_loss: 0.7051 - val_accuracy: 0.7215\n",
            "Epoch 4/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.7114 - accuracy: 0.7193 - val_loss: 0.6972 - val_accuracy: 0.7231\n",
            "Epoch 5/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.7042 - accuracy: 0.7210 - val_loss: 0.6910 - val_accuracy: 0.7243\n",
            "Epoch 6/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6995 - accuracy: 0.7218 - val_loss: 0.6885 - val_accuracy: 0.7247\n",
            "Epoch 7/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.6951 - accuracy: 0.7244 - val_loss: 0.6907 - val_accuracy: 0.7225\n",
            "Epoch 8/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.6911 - accuracy: 0.7246 - val_loss: 0.6868 - val_accuracy: 0.7240\n",
            "Epoch 9/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6857 - accuracy: 0.7271 - val_loss: 0.6794 - val_accuracy: 0.7263\n",
            "Epoch 10/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6815 - accuracy: 0.7287 - val_loss: 0.6803 - val_accuracy: 0.7240\n",
            "Epoch 11/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6806 - accuracy: 0.7281 - val_loss: 0.6738 - val_accuracy: 0.7293\n",
            "Epoch 12/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.6778 - accuracy: 0.7293 - val_loss: 0.6777 - val_accuracy: 0.7268\n",
            "Epoch 13/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.6735 - accuracy: 0.7309 - val_loss: 0.6762 - val_accuracy: 0.7247\n",
            "Epoch 14/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6714 - accuracy: 0.7316 - val_loss: 0.6706 - val_accuracy: 0.7271\n",
            "Epoch 15/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6666 - accuracy: 0.7336 - val_loss: 0.6619 - val_accuracy: 0.7333\n",
            "Epoch 16/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6634 - accuracy: 0.7350 - val_loss: 0.6601 - val_accuracy: 0.7340\n",
            "Epoch 17/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.6599 - accuracy: 0.7354 - val_loss: 0.6559 - val_accuracy: 0.7375\n",
            "Epoch 18/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.6586 - accuracy: 0.7354 - val_loss: 0.6609 - val_accuracy: 0.7337\n",
            "Epoch 19/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.6555 - accuracy: 0.7362 - val_loss: 0.6626 - val_accuracy: 0.7310\n",
            "Epoch 20/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6545 - accuracy: 0.7365 - val_loss: 0.6574 - val_accuracy: 0.7337\n",
            "Epoch 21/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6487 - accuracy: 0.7407 - val_loss: 0.6536 - val_accuracy: 0.7353\n",
            "Epoch 22/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6491 - accuracy: 0.7395 - val_loss: 0.6493 - val_accuracy: 0.7415\n",
            "Epoch 23/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.6439 - accuracy: 0.7404 - val_loss: 0.6502 - val_accuracy: 0.7356\n",
            "Epoch 24/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.6389 - accuracy: 0.7424 - val_loss: 0.6386 - val_accuracy: 0.7403\n",
            "Epoch 25/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6375 - accuracy: 0.7428 - val_loss: 0.6367 - val_accuracy: 0.7403\n",
            "Epoch 26/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6335 - accuracy: 0.7457 - val_loss: 0.6334 - val_accuracy: 0.7431\n",
            "Epoch 27/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6307 - accuracy: 0.7462 - val_loss: 0.6302 - val_accuracy: 0.7428\n",
            "Epoch 28/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.6278 - accuracy: 0.7468 - val_loss: 0.6319 - val_accuracy: 0.7432\n",
            "Epoch 29/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.6270 - accuracy: 0.7471 - val_loss: 0.6260 - val_accuracy: 0.7428\n",
            "Epoch 30/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6243 - accuracy: 0.7474 - val_loss: 0.6231 - val_accuracy: 0.7502\n",
            "Epoch 31/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6167 - accuracy: 0.7500 - val_loss: 0.6236 - val_accuracy: 0.7449\n",
            "Epoch 32/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6158 - accuracy: 0.7501 - val_loss: 0.6133 - val_accuracy: 0.7496\n",
            "Epoch 33/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.6131 - accuracy: 0.7512 - val_loss: 0.6168 - val_accuracy: 0.7447\n",
            "Epoch 34/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.6120 - accuracy: 0.7515 - val_loss: 0.6066 - val_accuracy: 0.7519\n",
            "Epoch 35/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.6069 - accuracy: 0.7543 - val_loss: 0.6153 - val_accuracy: 0.7504\n",
            "Epoch 36/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6060 - accuracy: 0.7543 - val_loss: 0.6065 - val_accuracy: 0.7515\n",
            "Epoch 37/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.6030 - accuracy: 0.7553 - val_loss: 0.6034 - val_accuracy: 0.7548\n",
            "Epoch 38/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5986 - accuracy: 0.7583 - val_loss: 0.6002 - val_accuracy: 0.7589\n",
            "Epoch 39/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.5970 - accuracy: 0.7564 - val_loss: 0.5994 - val_accuracy: 0.7588\n",
            "Epoch 40/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.5931 - accuracy: 0.7600 - val_loss: 0.5964 - val_accuracy: 0.7593\n",
            "Epoch 41/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5897 - accuracy: 0.7607 - val_loss: 0.5943 - val_accuracy: 0.7598\n",
            "Epoch 42/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5857 - accuracy: 0.7616 - val_loss: 0.5943 - val_accuracy: 0.7585\n",
            "Epoch 43/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5858 - accuracy: 0.7617 - val_loss: 0.5820 - val_accuracy: 0.7607\n",
            "Epoch 44/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.5801 - accuracy: 0.7639 - val_loss: 0.5855 - val_accuracy: 0.7612\n",
            "Epoch 45/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.5781 - accuracy: 0.7656 - val_loss: 0.5833 - val_accuracy: 0.7656\n",
            "Epoch 46/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5775 - accuracy: 0.7647 - val_loss: 0.5741 - val_accuracy: 0.7681\n",
            "Epoch 47/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5766 - accuracy: 0.7635 - val_loss: 0.5718 - val_accuracy: 0.7687\n",
            "Epoch 48/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5711 - accuracy: 0.7694 - val_loss: 0.5729 - val_accuracy: 0.7714\n",
            "Epoch 49/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5690 - accuracy: 0.7678 - val_loss: 0.5740 - val_accuracy: 0.7671\n",
            "Epoch 50/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.5673 - accuracy: 0.7699 - val_loss: 0.5703 - val_accuracy: 0.7702\n",
            "Epoch 51/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.5621 - accuracy: 0.7709 - val_loss: 0.5607 - val_accuracy: 0.7720\n",
            "Epoch 52/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5636 - accuracy: 0.7702 - val_loss: 0.5635 - val_accuracy: 0.7716\n",
            "Epoch 53/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5603 - accuracy: 0.7715 - val_loss: 0.5644 - val_accuracy: 0.7721\n",
            "Epoch 54/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5604 - accuracy: 0.7714 - val_loss: 0.5664 - val_accuracy: 0.7678\n",
            "Epoch 55/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.5535 - accuracy: 0.7759 - val_loss: 0.5609 - val_accuracy: 0.7732\n",
            "Epoch 56/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.5559 - accuracy: 0.7742 - val_loss: 0.5555 - val_accuracy: 0.7772\n",
            "Epoch 57/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5514 - accuracy: 0.7764 - val_loss: 0.5549 - val_accuracy: 0.7763\n",
            "Epoch 58/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5471 - accuracy: 0.7768 - val_loss: 0.5500 - val_accuracy: 0.7746\n",
            "Epoch 59/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5461 - accuracy: 0.7764 - val_loss: 0.5502 - val_accuracy: 0.7779\n",
            "Epoch 60/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.5458 - accuracy: 0.7776 - val_loss: 0.5428 - val_accuracy: 0.7810\n",
            "Epoch 61/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.5410 - accuracy: 0.7805 - val_loss: 0.5399 - val_accuracy: 0.7825\n",
            "Epoch 62/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5367 - accuracy: 0.7820 - val_loss: 0.5473 - val_accuracy: 0.7783\n",
            "Epoch 63/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5374 - accuracy: 0.7796 - val_loss: 0.5449 - val_accuracy: 0.7773\n",
            "Epoch 64/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5312 - accuracy: 0.7834 - val_loss: 0.5420 - val_accuracy: 0.7823\n",
            "Epoch 65/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5326 - accuracy: 0.7843 - val_loss: 0.5409 - val_accuracy: 0.7802\n",
            "Epoch 66/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.5327 - accuracy: 0.7852 - val_loss: 0.5369 - val_accuracy: 0.7829\n",
            "Epoch 67/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.5316 - accuracy: 0.7839 - val_loss: 0.5351 - val_accuracy: 0.7835\n",
            "Epoch 68/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5273 - accuracy: 0.7867 - val_loss: 0.5339 - val_accuracy: 0.7866\n",
            "Epoch 69/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5237 - accuracy: 0.7863 - val_loss: 0.5315 - val_accuracy: 0.7871\n",
            "Epoch 70/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5239 - accuracy: 0.7860 - val_loss: 0.5281 - val_accuracy: 0.7884\n",
            "Epoch 71/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.5207 - accuracy: 0.7855 - val_loss: 0.5378 - val_accuracy: 0.7853\n",
            "Epoch 72/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.5215 - accuracy: 0.7878 - val_loss: 0.5336 - val_accuracy: 0.7865\n",
            "Epoch 73/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5191 - accuracy: 0.7880 - val_loss: 0.5330 - val_accuracy: 0.7866\n",
            "Epoch 74/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.5190 - accuracy: 0.7868 - val_loss: 0.5321 - val_accuracy: 0.7876\n",
            "Epoch 75/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5171 - accuracy: 0.7900 - val_loss: 0.5220 - val_accuracy: 0.7925\n",
            "Epoch 76/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.5117 - accuracy: 0.7919 - val_loss: 0.5244 - val_accuracy: 0.7898\n",
            "Epoch 77/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.5100 - accuracy: 0.7927 - val_loss: 0.5243 - val_accuracy: 0.7906\n",
            "Epoch 78/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5106 - accuracy: 0.7921 - val_loss: 0.5184 - val_accuracy: 0.7923\n",
            "Epoch 79/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5060 - accuracy: 0.7947 - val_loss: 0.5189 - val_accuracy: 0.7939\n",
            "Epoch 80/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5102 - accuracy: 0.7921 - val_loss: 0.5171 - val_accuracy: 0.7919\n",
            "Epoch 81/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5028 - accuracy: 0.7969 - val_loss: 0.5227 - val_accuracy: 0.7906\n",
            "Epoch 82/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.5034 - accuracy: 0.7955 - val_loss: 0.5140 - val_accuracy: 0.7954\n",
            "Epoch 83/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.5004 - accuracy: 0.7947 - val_loss: 0.5127 - val_accuracy: 0.7940\n",
            "Epoch 84/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4999 - accuracy: 0.7988 - val_loss: 0.5115 - val_accuracy: 0.7975\n",
            "Epoch 85/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.5016 - accuracy: 0.7946 - val_loss: 0.5159 - val_accuracy: 0.7932\n",
            "Epoch 86/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4968 - accuracy: 0.7975 - val_loss: 0.5145 - val_accuracy: 0.7952\n",
            "Epoch 87/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.4936 - accuracy: 0.7993 - val_loss: 0.5052 - val_accuracy: 0.8004\n",
            "Epoch 88/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.4934 - accuracy: 0.7983 - val_loss: 0.5050 - val_accuracy: 0.7984\n",
            "Epoch 89/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4953 - accuracy: 0.7986 - val_loss: 0.5036 - val_accuracy: 0.7984\n",
            "Epoch 90/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4929 - accuracy: 0.8005 - val_loss: 0.5054 - val_accuracy: 0.7991\n",
            "Epoch 91/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4907 - accuracy: 0.7996 - val_loss: 0.5015 - val_accuracy: 0.7984\n",
            "Epoch 92/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4902 - accuracy: 0.8025 - val_loss: 0.5058 - val_accuracy: 0.7977\n",
            "Epoch 93/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4884 - accuracy: 0.8020 - val_loss: 0.5035 - val_accuracy: 0.8022\n",
            "Epoch 94/900\n",
            "93/93 [==============================] - 2s 25ms/step - loss: 0.4853 - accuracy: 0.8025 - val_loss: 0.5016 - val_accuracy: 0.7996\n",
            "Epoch 95/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4878 - accuracy: 0.8022 - val_loss: 0.5002 - val_accuracy: 0.8021\n",
            "Epoch 96/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4831 - accuracy: 0.8055 - val_loss: 0.5020 - val_accuracy: 0.7980\n",
            "Epoch 97/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4825 - accuracy: 0.8038 - val_loss: 0.4992 - val_accuracy: 0.8029\n",
            "Epoch 98/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4886 - accuracy: 0.8019 - val_loss: 0.4965 - val_accuracy: 0.8025\n",
            "Epoch 99/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4797 - accuracy: 0.8037 - val_loss: 0.5000 - val_accuracy: 0.8039\n",
            "Epoch 100/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4793 - accuracy: 0.8048 - val_loss: 0.4956 - val_accuracy: 0.8059\n",
            "Epoch 101/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4761 - accuracy: 0.8056 - val_loss: 0.4984 - val_accuracy: 0.8014\n",
            "Epoch 102/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4751 - accuracy: 0.8067 - val_loss: 0.4917 - val_accuracy: 0.8055\n",
            "Epoch 103/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4776 - accuracy: 0.8053 - val_loss: 0.4954 - val_accuracy: 0.8025\n",
            "Epoch 104/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.4790 - accuracy: 0.8066 - val_loss: 0.4969 - val_accuracy: 0.8015\n",
            "Epoch 105/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4757 - accuracy: 0.8073 - val_loss: 0.4937 - val_accuracy: 0.8032\n",
            "Epoch 106/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4748 - accuracy: 0.8073 - val_loss: 0.4882 - val_accuracy: 0.8066\n",
            "Epoch 107/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4682 - accuracy: 0.8089 - val_loss: 0.4915 - val_accuracy: 0.8092\n",
            "Epoch 108/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.4718 - accuracy: 0.8093 - val_loss: 0.4887 - val_accuracy: 0.8083\n",
            "Epoch 109/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4719 - accuracy: 0.8094 - val_loss: 0.4865 - val_accuracy: 0.8045\n",
            "Epoch 110/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4671 - accuracy: 0.8125 - val_loss: 0.4900 - val_accuracy: 0.8090\n",
            "Epoch 111/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4678 - accuracy: 0.8114 - val_loss: 0.4872 - val_accuracy: 0.8074\n",
            "Epoch 112/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4638 - accuracy: 0.8123 - val_loss: 0.4825 - val_accuracy: 0.8078\n",
            "Epoch 113/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.4667 - accuracy: 0.8100 - val_loss: 0.4878 - val_accuracy: 0.8099\n",
            "Epoch 114/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4661 - accuracy: 0.8103 - val_loss: 0.4810 - val_accuracy: 0.8070\n",
            "Epoch 115/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4616 - accuracy: 0.8134 - val_loss: 0.4836 - val_accuracy: 0.8085\n",
            "Epoch 116/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4596 - accuracy: 0.8146 - val_loss: 0.4741 - val_accuracy: 0.8107\n",
            "Epoch 117/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4579 - accuracy: 0.8139 - val_loss: 0.4773 - val_accuracy: 0.8096\n",
            "Epoch 118/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4601 - accuracy: 0.8134 - val_loss: 0.4824 - val_accuracy: 0.8101\n",
            "Epoch 119/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4596 - accuracy: 0.8140 - val_loss: 0.4777 - val_accuracy: 0.8133\n",
            "Epoch 120/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4608 - accuracy: 0.8144 - val_loss: 0.4794 - val_accuracy: 0.8138\n",
            "Epoch 121/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4584 - accuracy: 0.8157 - val_loss: 0.4819 - val_accuracy: 0.8095\n",
            "Epoch 122/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4584 - accuracy: 0.8156 - val_loss: 0.4784 - val_accuracy: 0.8134\n",
            "Epoch 123/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4519 - accuracy: 0.8178 - val_loss: 0.4798 - val_accuracy: 0.8128\n",
            "Epoch 124/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4554 - accuracy: 0.8160 - val_loss: 0.4810 - val_accuracy: 0.8085\n",
            "Epoch 125/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4550 - accuracy: 0.8163 - val_loss: 0.4705 - val_accuracy: 0.8126\n",
            "Epoch 126/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4556 - accuracy: 0.8159 - val_loss: 0.4742 - val_accuracy: 0.8161\n",
            "Epoch 127/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4554 - accuracy: 0.8153 - val_loss: 0.4750 - val_accuracy: 0.8117\n",
            "Epoch 128/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4512 - accuracy: 0.8174 - val_loss: 0.4749 - val_accuracy: 0.8145\n",
            "Epoch 129/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4518 - accuracy: 0.8177 - val_loss: 0.4743 - val_accuracy: 0.8129\n",
            "Epoch 130/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.4487 - accuracy: 0.8185 - val_loss: 0.4815 - val_accuracy: 0.8134\n",
            "Epoch 131/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4482 - accuracy: 0.8197 - val_loss: 0.4726 - val_accuracy: 0.8124\n",
            "Epoch 132/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4505 - accuracy: 0.8188 - val_loss: 0.4768 - val_accuracy: 0.8117\n",
            "Epoch 133/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4460 - accuracy: 0.8207 - val_loss: 0.4668 - val_accuracy: 0.8160\n",
            "Epoch 134/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.4447 - accuracy: 0.8211 - val_loss: 0.4720 - val_accuracy: 0.8154\n",
            "Epoch 135/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4451 - accuracy: 0.8212 - val_loss: 0.4685 - val_accuracy: 0.8176\n",
            "Epoch 136/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4422 - accuracy: 0.8225 - val_loss: 0.4654 - val_accuracy: 0.8178\n",
            "Epoch 137/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4429 - accuracy: 0.8212 - val_loss: 0.4711 - val_accuracy: 0.8173\n",
            "Epoch 138/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4421 - accuracy: 0.8218 - val_loss: 0.4714 - val_accuracy: 0.8196\n",
            "Epoch 139/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4427 - accuracy: 0.8234 - val_loss: 0.4693 - val_accuracy: 0.8172\n",
            "Epoch 140/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.4409 - accuracy: 0.8240 - val_loss: 0.4847 - val_accuracy: 0.8129\n",
            "Epoch 141/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4407 - accuracy: 0.8231 - val_loss: 0.4757 - val_accuracy: 0.8174\n",
            "Epoch 142/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4381 - accuracy: 0.8226 - val_loss: 0.4637 - val_accuracy: 0.8182\n",
            "Epoch 143/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4414 - accuracy: 0.8215 - val_loss: 0.4673 - val_accuracy: 0.8201\n",
            "Epoch 144/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4392 - accuracy: 0.8234 - val_loss: 0.4709 - val_accuracy: 0.8161\n",
            "Epoch 145/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4394 - accuracy: 0.8209 - val_loss: 0.4651 - val_accuracy: 0.8207\n",
            "Epoch 146/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.4387 - accuracy: 0.8229 - val_loss: 0.4632 - val_accuracy: 0.8157\n",
            "Epoch 147/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4401 - accuracy: 0.8237 - val_loss: 0.4653 - val_accuracy: 0.8205\n",
            "Epoch 148/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4353 - accuracy: 0.8249 - val_loss: 0.4691 - val_accuracy: 0.8186\n",
            "Epoch 149/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4342 - accuracy: 0.8274 - val_loss: 0.4592 - val_accuracy: 0.8226\n",
            "Epoch 150/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.4361 - accuracy: 0.8247 - val_loss: 0.4719 - val_accuracy: 0.8172\n",
            "Epoch 151/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4340 - accuracy: 0.8243 - val_loss: 0.4654 - val_accuracy: 0.8213\n",
            "Epoch 152/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4358 - accuracy: 0.8257 - val_loss: 0.4661 - val_accuracy: 0.8201\n",
            "Epoch 153/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4328 - accuracy: 0.8257 - val_loss: 0.4640 - val_accuracy: 0.8188\n",
            "Epoch 154/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4317 - accuracy: 0.8261 - val_loss: 0.4593 - val_accuracy: 0.8239\n",
            "Epoch 155/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.4315 - accuracy: 0.8271 - val_loss: 0.4652 - val_accuracy: 0.8199\n",
            "Epoch 156/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.4289 - accuracy: 0.8279 - val_loss: 0.4601 - val_accuracy: 0.8203\n",
            "Epoch 157/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4306 - accuracy: 0.8261 - val_loss: 0.4581 - val_accuracy: 0.8233\n",
            "Epoch 158/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4304 - accuracy: 0.8250 - val_loss: 0.4616 - val_accuracy: 0.8255\n",
            "Epoch 159/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4284 - accuracy: 0.8285 - val_loss: 0.4583 - val_accuracy: 0.8217\n",
            "Epoch 160/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4267 - accuracy: 0.8286 - val_loss: 0.4586 - val_accuracy: 0.8240\n",
            "Epoch 161/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4313 - accuracy: 0.8267 - val_loss: 0.4542 - val_accuracy: 0.8261\n",
            "Epoch 162/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4275 - accuracy: 0.8295 - val_loss: 0.4589 - val_accuracy: 0.8197\n",
            "Epoch 163/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4244 - accuracy: 0.8310 - val_loss: 0.4569 - val_accuracy: 0.8268\n",
            "Epoch 164/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4273 - accuracy: 0.8276 - val_loss: 0.4625 - val_accuracy: 0.8190\n",
            "Epoch 165/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4293 - accuracy: 0.8283 - val_loss: 0.4556 - val_accuracy: 0.8259\n",
            "Epoch 166/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.4252 - accuracy: 0.8312 - val_loss: 0.4615 - val_accuracy: 0.8215\n",
            "Epoch 167/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.4292 - accuracy: 0.8295 - val_loss: 0.4600 - val_accuracy: 0.8224\n",
            "Epoch 168/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4227 - accuracy: 0.8295 - val_loss: 0.4627 - val_accuracy: 0.8238\n",
            "Epoch 169/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.4227 - accuracy: 0.8306 - val_loss: 0.4580 - val_accuracy: 0.8239\n",
            "Epoch 170/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.4249 - accuracy: 0.8307 - val_loss: 0.4636 - val_accuracy: 0.8242\n",
            "Epoch 171/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.4224 - accuracy: 0.8301 - val_loss: 0.4577 - val_accuracy: 0.8265\n",
            "Epoch 172/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4228 - accuracy: 0.8298 - val_loss: 0.4596 - val_accuracy: 0.8239\n",
            "Epoch 173/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4220 - accuracy: 0.8296 - val_loss: 0.4549 - val_accuracy: 0.8228\n",
            "Epoch 174/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4205 - accuracy: 0.8322 - val_loss: 0.4575 - val_accuracy: 0.8251\n",
            "Epoch 175/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4186 - accuracy: 0.8318 - val_loss: 0.4597 - val_accuracy: 0.8247\n",
            "Epoch 176/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.4195 - accuracy: 0.8311 - val_loss: 0.4533 - val_accuracy: 0.8236\n",
            "Epoch 177/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.4179 - accuracy: 0.8324 - val_loss: 0.4545 - val_accuracy: 0.8272\n",
            "Epoch 178/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4163 - accuracy: 0.8334 - val_loss: 0.4547 - val_accuracy: 0.8270\n",
            "Epoch 179/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4188 - accuracy: 0.8324 - val_loss: 0.4567 - val_accuracy: 0.8273\n",
            "Epoch 180/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.4208 - accuracy: 0.8308 - val_loss: 0.4500 - val_accuracy: 0.8251\n",
            "Epoch 181/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.4175 - accuracy: 0.8317 - val_loss: 0.4559 - val_accuracy: 0.8240\n",
            "Epoch 182/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4126 - accuracy: 0.8346 - val_loss: 0.4562 - val_accuracy: 0.8286\n",
            "Epoch 183/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4171 - accuracy: 0.8330 - val_loss: 0.4512 - val_accuracy: 0.8254\n",
            "Epoch 184/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4172 - accuracy: 0.8331 - val_loss: 0.4527 - val_accuracy: 0.8280\n",
            "Epoch 185/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4165 - accuracy: 0.8326 - val_loss: 0.4555 - val_accuracy: 0.8240\n",
            "Epoch 186/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.4132 - accuracy: 0.8352 - val_loss: 0.4527 - val_accuracy: 0.8227\n",
            "Epoch 187/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.4143 - accuracy: 0.8340 - val_loss: 0.4602 - val_accuracy: 0.8258\n",
            "Epoch 188/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4179 - accuracy: 0.8327 - val_loss: 0.4505 - val_accuracy: 0.8295\n",
            "Epoch 189/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4082 - accuracy: 0.8362 - val_loss: 0.4460 - val_accuracy: 0.8340\n",
            "Epoch 190/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4099 - accuracy: 0.8365 - val_loss: 0.4515 - val_accuracy: 0.8289\n",
            "Epoch 191/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4086 - accuracy: 0.8371 - val_loss: 0.4585 - val_accuracy: 0.8248\n",
            "Epoch 192/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4147 - accuracy: 0.8333 - val_loss: 0.4482 - val_accuracy: 0.8288\n",
            "Epoch 193/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.4090 - accuracy: 0.8351 - val_loss: 0.4542 - val_accuracy: 0.8282\n",
            "Epoch 194/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4087 - accuracy: 0.8356 - val_loss: 0.4524 - val_accuracy: 0.8280\n",
            "Epoch 195/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4095 - accuracy: 0.8365 - val_loss: 0.4513 - val_accuracy: 0.8272\n",
            "Epoch 196/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4073 - accuracy: 0.8371 - val_loss: 0.4508 - val_accuracy: 0.8283\n",
            "Epoch 197/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4109 - accuracy: 0.8350 - val_loss: 0.4491 - val_accuracy: 0.8286\n",
            "Epoch 198/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.4111 - accuracy: 0.8347 - val_loss: 0.4497 - val_accuracy: 0.8290\n",
            "Epoch 199/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4072 - accuracy: 0.8363 - val_loss: 0.4514 - val_accuracy: 0.8264\n",
            "Epoch 200/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4058 - accuracy: 0.8382 - val_loss: 0.4476 - val_accuracy: 0.8246\n",
            "Epoch 201/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4043 - accuracy: 0.8392 - val_loss: 0.4477 - val_accuracy: 0.8286\n",
            "Epoch 202/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.4085 - accuracy: 0.8359 - val_loss: 0.4515 - val_accuracy: 0.8288\n",
            "Epoch 203/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.4074 - accuracy: 0.8372 - val_loss: 0.4470 - val_accuracy: 0.8303\n",
            "Epoch 204/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4066 - accuracy: 0.8381 - val_loss: 0.4477 - val_accuracy: 0.8307\n",
            "Epoch 205/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4038 - accuracy: 0.8387 - val_loss: 0.4436 - val_accuracy: 0.8296\n",
            "Epoch 206/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4032 - accuracy: 0.8399 - val_loss: 0.4430 - val_accuracy: 0.8309\n",
            "Epoch 207/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.4060 - accuracy: 0.8386 - val_loss: 0.4512 - val_accuracy: 0.8291\n",
            "Epoch 208/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.4037 - accuracy: 0.8388 - val_loss: 0.4502 - val_accuracy: 0.8286\n",
            "Epoch 209/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4072 - accuracy: 0.8359 - val_loss: 0.4465 - val_accuracy: 0.8322\n",
            "Epoch 210/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4010 - accuracy: 0.8398 - val_loss: 0.4530 - val_accuracy: 0.8278\n",
            "Epoch 211/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.4026 - accuracy: 0.8412 - val_loss: 0.4543 - val_accuracy: 0.8267\n",
            "Epoch 212/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.4002 - accuracy: 0.8412 - val_loss: 0.4529 - val_accuracy: 0.8282\n",
            "Epoch 213/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4004 - accuracy: 0.8408 - val_loss: 0.4430 - val_accuracy: 0.8339\n",
            "Epoch 214/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3972 - accuracy: 0.8408 - val_loss: 0.4469 - val_accuracy: 0.8285\n",
            "Epoch 215/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4001 - accuracy: 0.8400 - val_loss: 0.4454 - val_accuracy: 0.8302\n",
            "Epoch 216/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4024 - accuracy: 0.8393 - val_loss: 0.4426 - val_accuracy: 0.8323\n",
            "Epoch 217/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4010 - accuracy: 0.8405 - val_loss: 0.4412 - val_accuracy: 0.8318\n",
            "Epoch 218/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3973 - accuracy: 0.8401 - val_loss: 0.4511 - val_accuracy: 0.8283\n",
            "Epoch 219/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3992 - accuracy: 0.8425 - val_loss: 0.4469 - val_accuracy: 0.8301\n",
            "Epoch 220/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3994 - accuracy: 0.8394 - val_loss: 0.4497 - val_accuracy: 0.8334\n",
            "Epoch 221/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3986 - accuracy: 0.8412 - val_loss: 0.4487 - val_accuracy: 0.8317\n",
            "Epoch 222/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.4003 - accuracy: 0.8412 - val_loss: 0.4416 - val_accuracy: 0.8337\n",
            "Epoch 223/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3989 - accuracy: 0.8405 - val_loss: 0.4512 - val_accuracy: 0.8292\n",
            "Epoch 224/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3963 - accuracy: 0.8416 - val_loss: 0.4458 - val_accuracy: 0.8330\n",
            "Epoch 225/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3973 - accuracy: 0.8410 - val_loss: 0.4433 - val_accuracy: 0.8337\n",
            "Epoch 226/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3964 - accuracy: 0.8406 - val_loss: 0.4416 - val_accuracy: 0.8333\n",
            "Epoch 227/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3979 - accuracy: 0.8418 - val_loss: 0.4463 - val_accuracy: 0.8330\n",
            "Epoch 228/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3982 - accuracy: 0.8421 - val_loss: 0.4466 - val_accuracy: 0.8322\n",
            "Epoch 229/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3942 - accuracy: 0.8429 - val_loss: 0.4511 - val_accuracy: 0.8327\n",
            "Epoch 230/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3942 - accuracy: 0.8430 - val_loss: 0.4441 - val_accuracy: 0.8334\n",
            "Epoch 231/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3911 - accuracy: 0.8434 - val_loss: 0.4449 - val_accuracy: 0.8348\n",
            "Epoch 232/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3925 - accuracy: 0.8443 - val_loss: 0.4407 - val_accuracy: 0.8362\n",
            "Epoch 233/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3951 - accuracy: 0.8444 - val_loss: 0.4427 - val_accuracy: 0.8343\n",
            "Epoch 234/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3955 - accuracy: 0.8439 - val_loss: 0.4511 - val_accuracy: 0.8308\n",
            "Epoch 235/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3919 - accuracy: 0.8465 - val_loss: 0.4467 - val_accuracy: 0.8317\n",
            "Epoch 236/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3929 - accuracy: 0.8431 - val_loss: 0.4454 - val_accuracy: 0.8301\n",
            "Epoch 237/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3937 - accuracy: 0.8441 - val_loss: 0.4440 - val_accuracy: 0.8366\n",
            "Epoch 238/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3955 - accuracy: 0.8426 - val_loss: 0.4372 - val_accuracy: 0.8359\n",
            "Epoch 239/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3941 - accuracy: 0.8438 - val_loss: 0.4418 - val_accuracy: 0.8352\n",
            "Epoch 240/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3888 - accuracy: 0.8459 - val_loss: 0.4409 - val_accuracy: 0.8337\n",
            "Epoch 241/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3916 - accuracy: 0.8446 - val_loss: 0.4475 - val_accuracy: 0.8348\n",
            "Epoch 242/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3903 - accuracy: 0.8452 - val_loss: 0.4396 - val_accuracy: 0.8358\n",
            "Epoch 243/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3899 - accuracy: 0.8455 - val_loss: 0.4432 - val_accuracy: 0.8362\n",
            "Epoch 244/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3888 - accuracy: 0.8445 - val_loss: 0.4438 - val_accuracy: 0.8348\n",
            "Epoch 245/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3903 - accuracy: 0.8464 - val_loss: 0.4328 - val_accuracy: 0.8374\n",
            "Epoch 246/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3927 - accuracy: 0.8438 - val_loss: 0.4352 - val_accuracy: 0.8377\n",
            "Epoch 247/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3874 - accuracy: 0.8467 - val_loss: 0.4456 - val_accuracy: 0.8334\n",
            "Epoch 248/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3870 - accuracy: 0.8464 - val_loss: 0.4449 - val_accuracy: 0.8358\n",
            "Epoch 249/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3913 - accuracy: 0.8445 - val_loss: 0.4433 - val_accuracy: 0.8339\n",
            "Epoch 250/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3885 - accuracy: 0.8472 - val_loss: 0.4378 - val_accuracy: 0.8359\n",
            "Epoch 251/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3895 - accuracy: 0.8453 - val_loss: 0.4356 - val_accuracy: 0.8354\n",
            "Epoch 252/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3857 - accuracy: 0.8480 - val_loss: 0.4344 - val_accuracy: 0.8361\n",
            "Epoch 253/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3842 - accuracy: 0.8485 - val_loss: 0.4340 - val_accuracy: 0.8359\n",
            "Epoch 254/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3866 - accuracy: 0.8462 - val_loss: 0.4380 - val_accuracy: 0.8359\n",
            "Epoch 255/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3834 - accuracy: 0.8476 - val_loss: 0.4413 - val_accuracy: 0.8321\n",
            "Epoch 256/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3864 - accuracy: 0.8475 - val_loss: 0.4414 - val_accuracy: 0.8372\n",
            "Epoch 257/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3847 - accuracy: 0.8472 - val_loss: 0.4374 - val_accuracy: 0.8373\n",
            "Epoch 258/900\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.3853 - accuracy: 0.8456 - val_loss: 0.4361 - val_accuracy: 0.8402\n",
            "Epoch 259/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3862 - accuracy: 0.8454 - val_loss: 0.4352 - val_accuracy: 0.8377\n",
            "Epoch 260/900\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 0.3854 - accuracy: 0.8466 - val_loss: 0.4449 - val_accuracy: 0.8348\n",
            "Epoch 261/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3831 - accuracy: 0.8474 - val_loss: 0.4392 - val_accuracy: 0.8343\n",
            "Epoch 262/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3839 - accuracy: 0.8473 - val_loss: 0.4330 - val_accuracy: 0.8364\n",
            "Epoch 263/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3798 - accuracy: 0.8510 - val_loss: 0.4398 - val_accuracy: 0.8368\n",
            "Epoch 264/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3848 - accuracy: 0.8482 - val_loss: 0.4340 - val_accuracy: 0.8383\n",
            "Epoch 265/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3831 - accuracy: 0.8483 - val_loss: 0.4320 - val_accuracy: 0.8390\n",
            "Epoch 266/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3827 - accuracy: 0.8486 - val_loss: 0.4327 - val_accuracy: 0.8376\n",
            "Epoch 267/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3794 - accuracy: 0.8487 - val_loss: 0.4354 - val_accuracy: 0.8374\n",
            "Epoch 268/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3809 - accuracy: 0.8489 - val_loss: 0.4451 - val_accuracy: 0.8309\n",
            "Epoch 269/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3791 - accuracy: 0.8489 - val_loss: 0.4329 - val_accuracy: 0.8362\n",
            "Epoch 270/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3790 - accuracy: 0.8491 - val_loss: 0.4379 - val_accuracy: 0.8374\n",
            "Epoch 271/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3791 - accuracy: 0.8503 - val_loss: 0.4422 - val_accuracy: 0.8347\n",
            "Epoch 272/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3779 - accuracy: 0.8489 - val_loss: 0.4354 - val_accuracy: 0.8372\n",
            "Epoch 273/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3812 - accuracy: 0.8470 - val_loss: 0.4366 - val_accuracy: 0.8372\n",
            "Epoch 274/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3831 - accuracy: 0.8470 - val_loss: 0.4349 - val_accuracy: 0.8373\n",
            "Epoch 275/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3826 - accuracy: 0.8493 - val_loss: 0.4336 - val_accuracy: 0.8361\n",
            "Epoch 276/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3782 - accuracy: 0.8500 - val_loss: 0.4363 - val_accuracy: 0.8361\n",
            "Epoch 277/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3788 - accuracy: 0.8499 - val_loss: 0.4336 - val_accuracy: 0.8367\n",
            "Epoch 278/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3813 - accuracy: 0.8488 - val_loss: 0.4363 - val_accuracy: 0.8373\n",
            "Epoch 279/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3778 - accuracy: 0.8506 - val_loss: 0.4348 - val_accuracy: 0.8367\n",
            "Epoch 280/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3790 - accuracy: 0.8514 - val_loss: 0.4386 - val_accuracy: 0.8359\n",
            "Epoch 281/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3754 - accuracy: 0.8503 - val_loss: 0.4372 - val_accuracy: 0.8389\n",
            "Epoch 282/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3817 - accuracy: 0.8486 - val_loss: 0.4310 - val_accuracy: 0.8407\n",
            "Epoch 283/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3748 - accuracy: 0.8512 - val_loss: 0.4399 - val_accuracy: 0.8384\n",
            "Epoch 284/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3768 - accuracy: 0.8519 - val_loss: 0.4448 - val_accuracy: 0.8374\n",
            "Epoch 285/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3800 - accuracy: 0.8495 - val_loss: 0.4345 - val_accuracy: 0.8351\n",
            "Epoch 286/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3762 - accuracy: 0.8510 - val_loss: 0.4390 - val_accuracy: 0.8384\n",
            "Epoch 287/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3744 - accuracy: 0.8513 - val_loss: 0.4329 - val_accuracy: 0.8403\n",
            "Epoch 288/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3779 - accuracy: 0.8535 - val_loss: 0.4314 - val_accuracy: 0.8384\n",
            "Epoch 289/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3781 - accuracy: 0.8498 - val_loss: 0.4317 - val_accuracy: 0.8390\n",
            "Epoch 290/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3761 - accuracy: 0.8514 - val_loss: 0.4388 - val_accuracy: 0.8389\n",
            "Epoch 291/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3747 - accuracy: 0.8520 - val_loss: 0.4420 - val_accuracy: 0.8382\n",
            "Epoch 292/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3737 - accuracy: 0.8522 - val_loss: 0.4416 - val_accuracy: 0.8401\n",
            "Epoch 293/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3753 - accuracy: 0.8512 - val_loss: 0.4340 - val_accuracy: 0.8390\n",
            "Epoch 294/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3734 - accuracy: 0.8533 - val_loss: 0.4293 - val_accuracy: 0.8398\n",
            "Epoch 295/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3738 - accuracy: 0.8519 - val_loss: 0.4344 - val_accuracy: 0.8368\n",
            "Epoch 296/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3739 - accuracy: 0.8525 - val_loss: 0.4304 - val_accuracy: 0.8347\n",
            "Epoch 297/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3706 - accuracy: 0.8538 - val_loss: 0.4353 - val_accuracy: 0.8377\n",
            "Epoch 298/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3718 - accuracy: 0.8533 - val_loss: 0.4335 - val_accuracy: 0.8380\n",
            "Epoch 299/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3765 - accuracy: 0.8507 - val_loss: 0.4288 - val_accuracy: 0.8424\n",
            "Epoch 300/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3747 - accuracy: 0.8508 - val_loss: 0.4316 - val_accuracy: 0.8415\n",
            "Epoch 301/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3746 - accuracy: 0.8521 - val_loss: 0.4360 - val_accuracy: 0.8390\n",
            "Epoch 302/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3752 - accuracy: 0.8504 - val_loss: 0.4321 - val_accuracy: 0.8380\n",
            "Epoch 303/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3717 - accuracy: 0.8525 - val_loss: 0.4332 - val_accuracy: 0.8398\n",
            "Epoch 304/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3743 - accuracy: 0.8526 - val_loss: 0.4299 - val_accuracy: 0.8389\n",
            "Epoch 305/900\n",
            "93/93 [==============================] - 2s 27ms/step - loss: 0.3724 - accuracy: 0.8529 - val_loss: 0.4299 - val_accuracy: 0.8392\n",
            "Epoch 306/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3709 - accuracy: 0.8533 - val_loss: 0.4383 - val_accuracy: 0.8379\n",
            "Epoch 307/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3698 - accuracy: 0.8541 - val_loss: 0.4338 - val_accuracy: 0.8383\n",
            "Epoch 308/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3748 - accuracy: 0.8510 - val_loss: 0.4365 - val_accuracy: 0.8424\n",
            "Epoch 309/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3726 - accuracy: 0.8520 - val_loss: 0.4255 - val_accuracy: 0.8409\n",
            "Epoch 310/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3692 - accuracy: 0.8528 - val_loss: 0.4375 - val_accuracy: 0.8426\n",
            "Epoch 311/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3689 - accuracy: 0.8540 - val_loss: 0.4330 - val_accuracy: 0.8408\n",
            "Epoch 312/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3689 - accuracy: 0.8532 - val_loss: 0.4350 - val_accuracy: 0.8404\n",
            "Epoch 313/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3682 - accuracy: 0.8524 - val_loss: 0.4368 - val_accuracy: 0.8417\n",
            "Epoch 314/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3694 - accuracy: 0.8537 - val_loss: 0.4300 - val_accuracy: 0.8390\n",
            "Epoch 315/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3703 - accuracy: 0.8536 - val_loss: 0.4305 - val_accuracy: 0.8415\n",
            "Epoch 316/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3708 - accuracy: 0.8532 - val_loss: 0.4285 - val_accuracy: 0.8398\n",
            "Epoch 317/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3648 - accuracy: 0.8571 - val_loss: 0.4266 - val_accuracy: 0.8442\n",
            "Epoch 318/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3703 - accuracy: 0.8539 - val_loss: 0.4341 - val_accuracy: 0.8367\n",
            "Epoch 319/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3689 - accuracy: 0.8540 - val_loss: 0.4331 - val_accuracy: 0.8390\n",
            "Epoch 320/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3702 - accuracy: 0.8530 - val_loss: 0.4377 - val_accuracy: 0.8364\n",
            "Epoch 321/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3681 - accuracy: 0.8544 - val_loss: 0.4251 - val_accuracy: 0.8443\n",
            "Epoch 322/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3673 - accuracy: 0.8549 - val_loss: 0.4292 - val_accuracy: 0.8435\n",
            "Epoch 323/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3665 - accuracy: 0.8553 - val_loss: 0.4340 - val_accuracy: 0.8397\n",
            "Epoch 324/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3678 - accuracy: 0.8544 - val_loss: 0.4348 - val_accuracy: 0.8405\n",
            "Epoch 325/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3615 - accuracy: 0.8558 - val_loss: 0.4272 - val_accuracy: 0.8420\n",
            "Epoch 326/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3684 - accuracy: 0.8533 - val_loss: 0.4392 - val_accuracy: 0.8411\n",
            "Epoch 327/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3681 - accuracy: 0.8545 - val_loss: 0.4310 - val_accuracy: 0.8416\n",
            "Epoch 328/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3654 - accuracy: 0.8556 - val_loss: 0.4371 - val_accuracy: 0.8397\n",
            "Epoch 329/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3643 - accuracy: 0.8551 - val_loss: 0.4334 - val_accuracy: 0.8423\n",
            "Epoch 330/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3678 - accuracy: 0.8550 - val_loss: 0.4315 - val_accuracy: 0.8411\n",
            "Epoch 331/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3688 - accuracy: 0.8532 - val_loss: 0.4378 - val_accuracy: 0.8376\n",
            "Epoch 332/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3671 - accuracy: 0.8548 - val_loss: 0.4310 - val_accuracy: 0.8412\n",
            "Epoch 333/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3611 - accuracy: 0.8570 - val_loss: 0.4345 - val_accuracy: 0.8410\n",
            "Epoch 334/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3645 - accuracy: 0.8570 - val_loss: 0.4251 - val_accuracy: 0.8421\n",
            "Epoch 335/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3632 - accuracy: 0.8559 - val_loss: 0.4320 - val_accuracy: 0.8429\n",
            "Epoch 336/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3615 - accuracy: 0.8570 - val_loss: 0.4290 - val_accuracy: 0.8417\n",
            "Epoch 337/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3655 - accuracy: 0.8553 - val_loss: 0.4265 - val_accuracy: 0.8409\n",
            "Epoch 338/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3642 - accuracy: 0.8548 - val_loss: 0.4278 - val_accuracy: 0.8446\n",
            "Epoch 339/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3615 - accuracy: 0.8565 - val_loss: 0.4286 - val_accuracy: 0.8415\n",
            "Epoch 340/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3635 - accuracy: 0.8570 - val_loss: 0.4245 - val_accuracy: 0.8424\n",
            "Epoch 341/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3644 - accuracy: 0.8569 - val_loss: 0.4287 - val_accuracy: 0.8424\n",
            "Epoch 342/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3639 - accuracy: 0.8572 - val_loss: 0.4267 - val_accuracy: 0.8389\n",
            "Epoch 343/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3597 - accuracy: 0.8590 - val_loss: 0.4292 - val_accuracy: 0.8437\n",
            "Epoch 344/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3666 - accuracy: 0.8550 - val_loss: 0.4362 - val_accuracy: 0.8370\n",
            "Epoch 345/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3628 - accuracy: 0.8561 - val_loss: 0.4322 - val_accuracy: 0.8408\n",
            "Epoch 346/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3626 - accuracy: 0.8566 - val_loss: 0.4342 - val_accuracy: 0.8411\n",
            "Epoch 347/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3618 - accuracy: 0.8569 - val_loss: 0.4293 - val_accuracy: 0.8426\n",
            "Epoch 348/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3631 - accuracy: 0.8578 - val_loss: 0.4255 - val_accuracy: 0.8434\n",
            "Epoch 349/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3613 - accuracy: 0.8579 - val_loss: 0.4323 - val_accuracy: 0.8442\n",
            "Epoch 350/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3611 - accuracy: 0.8581 - val_loss: 0.4266 - val_accuracy: 0.8433\n",
            "Epoch 351/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3608 - accuracy: 0.8561 - val_loss: 0.4281 - val_accuracy: 0.8421\n",
            "Epoch 352/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3592 - accuracy: 0.8573 - val_loss: 0.4285 - val_accuracy: 0.8408\n",
            "Epoch 353/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3595 - accuracy: 0.8586 - val_loss: 0.4367 - val_accuracy: 0.8414\n",
            "Epoch 354/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3688 - accuracy: 0.8535 - val_loss: 0.4325 - val_accuracy: 0.8430\n",
            "Epoch 355/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3587 - accuracy: 0.8576 - val_loss: 0.4322 - val_accuracy: 0.8432\n",
            "Epoch 356/900\n",
            "93/93 [==============================] - 3s 27ms/step - loss: 0.3597 - accuracy: 0.8588 - val_loss: 0.4282 - val_accuracy: 0.8408\n",
            "Epoch 357/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3556 - accuracy: 0.8598 - val_loss: 0.4379 - val_accuracy: 0.8414\n",
            "Epoch 358/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3627 - accuracy: 0.8565 - val_loss: 0.4308 - val_accuracy: 0.8435\n",
            "Epoch 359/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3620 - accuracy: 0.8582 - val_loss: 0.4320 - val_accuracy: 0.8432\n",
            "Epoch 360/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3624 - accuracy: 0.8577 - val_loss: 0.4276 - val_accuracy: 0.8404\n",
            "Epoch 361/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3603 - accuracy: 0.8586 - val_loss: 0.4321 - val_accuracy: 0.8420\n",
            "Epoch 362/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3566 - accuracy: 0.8594 - val_loss: 0.4304 - val_accuracy: 0.8409\n",
            "Epoch 363/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3603 - accuracy: 0.8577 - val_loss: 0.4289 - val_accuracy: 0.8443\n",
            "Epoch 364/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3540 - accuracy: 0.8609 - val_loss: 0.4278 - val_accuracy: 0.8404\n",
            "Epoch 365/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3583 - accuracy: 0.8600 - val_loss: 0.4295 - val_accuracy: 0.8428\n",
            "Epoch 366/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3580 - accuracy: 0.8599 - val_loss: 0.4372 - val_accuracy: 0.8422\n",
            "Epoch 367/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3578 - accuracy: 0.8581 - val_loss: 0.4341 - val_accuracy: 0.8430\n",
            "Epoch 368/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3518 - accuracy: 0.8628 - val_loss: 0.4326 - val_accuracy: 0.8435\n",
            "Epoch 369/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3606 - accuracy: 0.8582 - val_loss: 0.4229 - val_accuracy: 0.8445\n",
            "Epoch 370/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3563 - accuracy: 0.8607 - val_loss: 0.4292 - val_accuracy: 0.8418\n",
            "Epoch 371/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3572 - accuracy: 0.8588 - val_loss: 0.4251 - val_accuracy: 0.8484\n",
            "Epoch 372/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3575 - accuracy: 0.8577 - val_loss: 0.4322 - val_accuracy: 0.8432\n",
            "Epoch 373/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3568 - accuracy: 0.8596 - val_loss: 0.4308 - val_accuracy: 0.8430\n",
            "Epoch 374/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3567 - accuracy: 0.8592 - val_loss: 0.4309 - val_accuracy: 0.8451\n",
            "Epoch 375/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3549 - accuracy: 0.8602 - val_loss: 0.4259 - val_accuracy: 0.8458\n",
            "Epoch 376/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3544 - accuracy: 0.8621 - val_loss: 0.4313 - val_accuracy: 0.8428\n",
            "Epoch 377/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3556 - accuracy: 0.8598 - val_loss: 0.4293 - val_accuracy: 0.8449\n",
            "Epoch 378/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3561 - accuracy: 0.8615 - val_loss: 0.4284 - val_accuracy: 0.8455\n",
            "Epoch 379/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3543 - accuracy: 0.8604 - val_loss: 0.4288 - val_accuracy: 0.8437\n",
            "Epoch 380/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3547 - accuracy: 0.8621 - val_loss: 0.4284 - val_accuracy: 0.8415\n",
            "Epoch 381/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3594 - accuracy: 0.8582 - val_loss: 0.4253 - val_accuracy: 0.8454\n",
            "Epoch 382/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3576 - accuracy: 0.8596 - val_loss: 0.4246 - val_accuracy: 0.8452\n",
            "Epoch 383/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3555 - accuracy: 0.8600 - val_loss: 0.4266 - val_accuracy: 0.8461\n",
            "Epoch 384/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3590 - accuracy: 0.8601 - val_loss: 0.4318 - val_accuracy: 0.8432\n",
            "Epoch 385/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3535 - accuracy: 0.8601 - val_loss: 0.4274 - val_accuracy: 0.8432\n",
            "Epoch 386/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3534 - accuracy: 0.8611 - val_loss: 0.4296 - val_accuracy: 0.8446\n",
            "Epoch 387/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3582 - accuracy: 0.8572 - val_loss: 0.4348 - val_accuracy: 0.8411\n",
            "Epoch 388/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3546 - accuracy: 0.8600 - val_loss: 0.4261 - val_accuracy: 0.8448\n",
            "Epoch 389/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3565 - accuracy: 0.8599 - val_loss: 0.4215 - val_accuracy: 0.8453\n",
            "Epoch 390/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3528 - accuracy: 0.8616 - val_loss: 0.4275 - val_accuracy: 0.8449\n",
            "Epoch 391/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3542 - accuracy: 0.8612 - val_loss: 0.4310 - val_accuracy: 0.8454\n",
            "Epoch 392/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3539 - accuracy: 0.8612 - val_loss: 0.4297 - val_accuracy: 0.8437\n",
            "Epoch 393/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3510 - accuracy: 0.8617 - val_loss: 0.4289 - val_accuracy: 0.8445\n",
            "Epoch 394/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3544 - accuracy: 0.8594 - val_loss: 0.4365 - val_accuracy: 0.8440\n",
            "Epoch 395/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3544 - accuracy: 0.8601 - val_loss: 0.4293 - val_accuracy: 0.8422\n",
            "Epoch 396/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3482 - accuracy: 0.8627 - val_loss: 0.4291 - val_accuracy: 0.8461\n",
            "Epoch 397/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3531 - accuracy: 0.8602 - val_loss: 0.4309 - val_accuracy: 0.8452\n",
            "Epoch 398/900\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 0.3498 - accuracy: 0.8643 - val_loss: 0.4273 - val_accuracy: 0.8437\n",
            "Epoch 399/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3512 - accuracy: 0.8612 - val_loss: 0.4271 - val_accuracy: 0.8474\n",
            "Epoch 400/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3515 - accuracy: 0.8618 - val_loss: 0.4328 - val_accuracy: 0.8447\n",
            "Epoch 401/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3535 - accuracy: 0.8608 - val_loss: 0.4312 - val_accuracy: 0.8440\n",
            "Epoch 402/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3495 - accuracy: 0.8633 - val_loss: 0.4263 - val_accuracy: 0.8455\n",
            "Epoch 403/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3529 - accuracy: 0.8611 - val_loss: 0.4227 - val_accuracy: 0.8464\n",
            "Epoch 404/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3476 - accuracy: 0.8622 - val_loss: 0.4225 - val_accuracy: 0.8486\n",
            "Epoch 405/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3529 - accuracy: 0.8604 - val_loss: 0.4235 - val_accuracy: 0.8461\n",
            "Epoch 406/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3536 - accuracy: 0.8615 - val_loss: 0.4194 - val_accuracy: 0.8490\n",
            "Epoch 407/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3527 - accuracy: 0.8610 - val_loss: 0.4223 - val_accuracy: 0.8470\n",
            "Epoch 408/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3472 - accuracy: 0.8627 - val_loss: 0.4256 - val_accuracy: 0.8451\n",
            "Epoch 409/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3491 - accuracy: 0.8631 - val_loss: 0.4214 - val_accuracy: 0.8478\n",
            "Epoch 410/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3489 - accuracy: 0.8623 - val_loss: 0.4325 - val_accuracy: 0.8458\n",
            "Epoch 411/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3486 - accuracy: 0.8632 - val_loss: 0.4248 - val_accuracy: 0.8427\n",
            "Epoch 412/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3486 - accuracy: 0.8628 - val_loss: 0.4259 - val_accuracy: 0.8446\n",
            "Epoch 413/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3489 - accuracy: 0.8630 - val_loss: 0.4275 - val_accuracy: 0.8481\n",
            "Epoch 414/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3534 - accuracy: 0.8620 - val_loss: 0.4243 - val_accuracy: 0.8459\n",
            "Epoch 415/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3531 - accuracy: 0.8607 - val_loss: 0.4231 - val_accuracy: 0.8465\n",
            "Epoch 416/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3498 - accuracy: 0.8626 - val_loss: 0.4239 - val_accuracy: 0.8453\n",
            "Epoch 417/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3483 - accuracy: 0.8640 - val_loss: 0.4296 - val_accuracy: 0.8446\n",
            "Epoch 418/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3499 - accuracy: 0.8622 - val_loss: 0.4309 - val_accuracy: 0.8432\n",
            "Epoch 419/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3484 - accuracy: 0.8643 - val_loss: 0.4268 - val_accuracy: 0.8464\n",
            "Epoch 420/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3468 - accuracy: 0.8655 - val_loss: 0.4201 - val_accuracy: 0.8473\n",
            "Epoch 421/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3455 - accuracy: 0.8630 - val_loss: 0.4253 - val_accuracy: 0.8476\n",
            "Epoch 422/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3472 - accuracy: 0.8640 - val_loss: 0.4274 - val_accuracy: 0.8462\n",
            "Epoch 423/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3499 - accuracy: 0.8637 - val_loss: 0.4257 - val_accuracy: 0.8478\n",
            "Epoch 424/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3464 - accuracy: 0.8645 - val_loss: 0.4230 - val_accuracy: 0.8472\n",
            "Epoch 425/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3472 - accuracy: 0.8655 - val_loss: 0.4173 - val_accuracy: 0.8477\n",
            "Epoch 426/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3498 - accuracy: 0.8631 - val_loss: 0.4206 - val_accuracy: 0.8470\n",
            "Epoch 427/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3434 - accuracy: 0.8634 - val_loss: 0.4255 - val_accuracy: 0.8458\n",
            "Epoch 428/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3463 - accuracy: 0.8642 - val_loss: 0.4224 - val_accuracy: 0.8461\n",
            "Epoch 429/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3442 - accuracy: 0.8627 - val_loss: 0.4257 - val_accuracy: 0.8439\n",
            "Epoch 430/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3459 - accuracy: 0.8656 - val_loss: 0.4310 - val_accuracy: 0.8467\n",
            "Epoch 431/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3501 - accuracy: 0.8623 - val_loss: 0.4254 - val_accuracy: 0.8459\n",
            "Epoch 432/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3457 - accuracy: 0.8636 - val_loss: 0.4245 - val_accuracy: 0.8458\n",
            "Epoch 433/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3458 - accuracy: 0.8654 - val_loss: 0.4225 - val_accuracy: 0.8457\n",
            "Epoch 434/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3476 - accuracy: 0.8644 - val_loss: 0.4308 - val_accuracy: 0.8460\n",
            "Epoch 435/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3414 - accuracy: 0.8649 - val_loss: 0.4246 - val_accuracy: 0.8428\n",
            "Epoch 436/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3451 - accuracy: 0.8645 - val_loss: 0.4213 - val_accuracy: 0.8462\n",
            "Epoch 437/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3437 - accuracy: 0.8645 - val_loss: 0.4190 - val_accuracy: 0.8476\n",
            "Epoch 438/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3452 - accuracy: 0.8635 - val_loss: 0.4178 - val_accuracy: 0.8461\n",
            "Epoch 439/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3428 - accuracy: 0.8652 - val_loss: 0.4174 - val_accuracy: 0.8461\n",
            "Epoch 440/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3423 - accuracy: 0.8646 - val_loss: 0.4246 - val_accuracy: 0.8441\n",
            "Epoch 441/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3447 - accuracy: 0.8650 - val_loss: 0.4230 - val_accuracy: 0.8498\n",
            "Epoch 442/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3456 - accuracy: 0.8640 - val_loss: 0.4226 - val_accuracy: 0.8479\n",
            "Epoch 443/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3462 - accuracy: 0.8638 - val_loss: 0.4192 - val_accuracy: 0.8498\n",
            "Epoch 444/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3458 - accuracy: 0.8634 - val_loss: 0.4210 - val_accuracy: 0.8479\n",
            "Epoch 445/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3460 - accuracy: 0.8648 - val_loss: 0.4255 - val_accuracy: 0.8461\n",
            "Epoch 446/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3406 - accuracy: 0.8659 - val_loss: 0.4233 - val_accuracy: 0.8473\n",
            "Epoch 447/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3460 - accuracy: 0.8634 - val_loss: 0.4204 - val_accuracy: 0.8448\n",
            "Epoch 448/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3437 - accuracy: 0.8648 - val_loss: 0.4182 - val_accuracy: 0.8452\n",
            "Epoch 449/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3458 - accuracy: 0.8650 - val_loss: 0.4253 - val_accuracy: 0.8447\n",
            "Epoch 450/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3424 - accuracy: 0.8652 - val_loss: 0.4241 - val_accuracy: 0.8477\n",
            "Epoch 451/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3399 - accuracy: 0.8678 - val_loss: 0.4270 - val_accuracy: 0.8486\n",
            "Epoch 452/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3442 - accuracy: 0.8654 - val_loss: 0.4183 - val_accuracy: 0.8497\n",
            "Epoch 453/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3431 - accuracy: 0.8657 - val_loss: 0.4208 - val_accuracy: 0.8502\n",
            "Epoch 454/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3423 - accuracy: 0.8662 - val_loss: 0.4286 - val_accuracy: 0.8454\n",
            "Epoch 455/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3432 - accuracy: 0.8655 - val_loss: 0.4196 - val_accuracy: 0.8481\n",
            "Epoch 456/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3437 - accuracy: 0.8674 - val_loss: 0.4235 - val_accuracy: 0.8493\n",
            "Epoch 457/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3432 - accuracy: 0.8659 - val_loss: 0.4249 - val_accuracy: 0.8489\n",
            "Epoch 458/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3432 - accuracy: 0.8649 - val_loss: 0.4291 - val_accuracy: 0.8464\n",
            "Epoch 459/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3413 - accuracy: 0.8662 - val_loss: 0.4283 - val_accuracy: 0.8437\n",
            "Epoch 460/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3419 - accuracy: 0.8659 - val_loss: 0.4199 - val_accuracy: 0.8495\n",
            "Epoch 461/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3411 - accuracy: 0.8667 - val_loss: 0.4388 - val_accuracy: 0.8458\n",
            "Epoch 462/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3440 - accuracy: 0.8649 - val_loss: 0.4231 - val_accuracy: 0.8462\n",
            "Epoch 463/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3385 - accuracy: 0.8682 - val_loss: 0.4215 - val_accuracy: 0.8462\n",
            "Epoch 464/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3412 - accuracy: 0.8670 - val_loss: 0.4221 - val_accuracy: 0.8465\n",
            "Epoch 465/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3425 - accuracy: 0.8657 - val_loss: 0.4273 - val_accuracy: 0.8459\n",
            "Epoch 466/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3437 - accuracy: 0.8645 - val_loss: 0.4184 - val_accuracy: 0.8493\n",
            "Epoch 467/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3394 - accuracy: 0.8669 - val_loss: 0.4211 - val_accuracy: 0.8492\n",
            "Epoch 468/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3461 - accuracy: 0.8626 - val_loss: 0.4240 - val_accuracy: 0.8497\n",
            "Epoch 469/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3404 - accuracy: 0.8683 - val_loss: 0.4172 - val_accuracy: 0.8470\n",
            "Epoch 470/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3435 - accuracy: 0.8666 - val_loss: 0.4291 - val_accuracy: 0.8440\n",
            "Epoch 471/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3413 - accuracy: 0.8661 - val_loss: 0.4215 - val_accuracy: 0.8490\n",
            "Epoch 472/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3404 - accuracy: 0.8664 - val_loss: 0.4265 - val_accuracy: 0.8465\n",
            "Epoch 473/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3392 - accuracy: 0.8661 - val_loss: 0.4250 - val_accuracy: 0.8491\n",
            "Epoch 474/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3393 - accuracy: 0.8657 - val_loss: 0.4356 - val_accuracy: 0.8470\n",
            "Epoch 475/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3366 - accuracy: 0.8682 - val_loss: 0.4297 - val_accuracy: 0.8485\n",
            "Epoch 476/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3437 - accuracy: 0.8655 - val_loss: 0.4252 - val_accuracy: 0.8489\n",
            "Epoch 477/900\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 0.3439 - accuracy: 0.8657 - val_loss: 0.4290 - val_accuracy: 0.8472\n",
            "Epoch 478/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3381 - accuracy: 0.8663 - val_loss: 0.4270 - val_accuracy: 0.8487\n",
            "Epoch 479/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3352 - accuracy: 0.8689 - val_loss: 0.4186 - val_accuracy: 0.8473\n",
            "Epoch 480/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3407 - accuracy: 0.8669 - val_loss: 0.4242 - val_accuracy: 0.8491\n",
            "Epoch 481/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3412 - accuracy: 0.8670 - val_loss: 0.4135 - val_accuracy: 0.8501\n",
            "Epoch 482/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3351 - accuracy: 0.8683 - val_loss: 0.4209 - val_accuracy: 0.8467\n",
            "Epoch 483/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3391 - accuracy: 0.8676 - val_loss: 0.4240 - val_accuracy: 0.8479\n",
            "Epoch 484/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3389 - accuracy: 0.8686 - val_loss: 0.4163 - val_accuracy: 0.8490\n",
            "Epoch 485/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3385 - accuracy: 0.8674 - val_loss: 0.4199 - val_accuracy: 0.8486\n",
            "Epoch 486/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3379 - accuracy: 0.8665 - val_loss: 0.4160 - val_accuracy: 0.8495\n",
            "Epoch 487/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3355 - accuracy: 0.8691 - val_loss: 0.4258 - val_accuracy: 0.8483\n",
            "Epoch 488/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3360 - accuracy: 0.8684 - val_loss: 0.4289 - val_accuracy: 0.8481\n",
            "Epoch 489/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3360 - accuracy: 0.8677 - val_loss: 0.4297 - val_accuracy: 0.8436\n",
            "Epoch 490/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3328 - accuracy: 0.8700 - val_loss: 0.4179 - val_accuracy: 0.8483\n",
            "Epoch 491/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3407 - accuracy: 0.8666 - val_loss: 0.4188 - val_accuracy: 0.8484\n",
            "Epoch 492/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3347 - accuracy: 0.8689 - val_loss: 0.4226 - val_accuracy: 0.8491\n",
            "Epoch 493/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3366 - accuracy: 0.8685 - val_loss: 0.4207 - val_accuracy: 0.8479\n",
            "Epoch 494/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3399 - accuracy: 0.8671 - val_loss: 0.4117 - val_accuracy: 0.8497\n",
            "Epoch 495/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3399 - accuracy: 0.8679 - val_loss: 0.4200 - val_accuracy: 0.8496\n",
            "Epoch 496/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3385 - accuracy: 0.8656 - val_loss: 0.4157 - val_accuracy: 0.8499\n",
            "Epoch 497/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3367 - accuracy: 0.8683 - val_loss: 0.4228 - val_accuracy: 0.8480\n",
            "Epoch 498/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3349 - accuracy: 0.8679 - val_loss: 0.4183 - val_accuracy: 0.8470\n",
            "Epoch 499/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3362 - accuracy: 0.8683 - val_loss: 0.4259 - val_accuracy: 0.8468\n",
            "Epoch 500/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3326 - accuracy: 0.8702 - val_loss: 0.4266 - val_accuracy: 0.8484\n",
            "Epoch 501/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3339 - accuracy: 0.8676 - val_loss: 0.4338 - val_accuracy: 0.8458\n",
            "Epoch 502/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3354 - accuracy: 0.8694 - val_loss: 0.4296 - val_accuracy: 0.8445\n",
            "Epoch 503/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3357 - accuracy: 0.8691 - val_loss: 0.4198 - val_accuracy: 0.8483\n",
            "Epoch 504/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3350 - accuracy: 0.8679 - val_loss: 0.4235 - val_accuracy: 0.8510\n",
            "Epoch 505/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3346 - accuracy: 0.8667 - val_loss: 0.4199 - val_accuracy: 0.8462\n",
            "Epoch 506/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3384 - accuracy: 0.8671 - val_loss: 0.4178 - val_accuracy: 0.8451\n",
            "Epoch 507/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3311 - accuracy: 0.8695 - val_loss: 0.4208 - val_accuracy: 0.8489\n",
            "Epoch 508/900\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 0.3328 - accuracy: 0.8685 - val_loss: 0.4252 - val_accuracy: 0.8477\n",
            "Epoch 509/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3392 - accuracy: 0.8696 - val_loss: 0.4258 - val_accuracy: 0.8476\n",
            "Epoch 510/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3373 - accuracy: 0.8697 - val_loss: 0.4193 - val_accuracy: 0.8487\n",
            "Epoch 511/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3364 - accuracy: 0.8695 - val_loss: 0.4234 - val_accuracy: 0.8448\n",
            "Epoch 512/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3307 - accuracy: 0.8710 - val_loss: 0.4197 - val_accuracy: 0.8502\n",
            "Epoch 513/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3339 - accuracy: 0.8700 - val_loss: 0.4311 - val_accuracy: 0.8467\n",
            "Epoch 514/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3378 - accuracy: 0.8690 - val_loss: 0.4181 - val_accuracy: 0.8535\n",
            "Epoch 515/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3313 - accuracy: 0.8702 - val_loss: 0.4213 - val_accuracy: 0.8471\n",
            "Epoch 516/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3339 - accuracy: 0.8696 - val_loss: 0.4282 - val_accuracy: 0.8509\n",
            "Epoch 517/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3315 - accuracy: 0.8707 - val_loss: 0.4152 - val_accuracy: 0.8498\n",
            "Epoch 518/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3340 - accuracy: 0.8702 - val_loss: 0.4212 - val_accuracy: 0.8489\n",
            "Epoch 519/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3335 - accuracy: 0.8705 - val_loss: 0.4234 - val_accuracy: 0.8497\n",
            "Epoch 520/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3337 - accuracy: 0.8695 - val_loss: 0.4179 - val_accuracy: 0.8483\n",
            "Epoch 521/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3359 - accuracy: 0.8680 - val_loss: 0.4182 - val_accuracy: 0.8495\n",
            "Epoch 522/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3344 - accuracy: 0.8693 - val_loss: 0.4251 - val_accuracy: 0.8462\n",
            "Epoch 523/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3352 - accuracy: 0.8676 - val_loss: 0.4213 - val_accuracy: 0.8492\n",
            "Epoch 524/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3310 - accuracy: 0.8707 - val_loss: 0.4239 - val_accuracy: 0.8505\n",
            "Epoch 525/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3351 - accuracy: 0.8681 - val_loss: 0.4306 - val_accuracy: 0.8472\n",
            "Epoch 526/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3365 - accuracy: 0.8682 - val_loss: 0.4234 - val_accuracy: 0.8491\n",
            "Epoch 527/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3294 - accuracy: 0.8696 - val_loss: 0.4213 - val_accuracy: 0.8474\n",
            "Epoch 528/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3332 - accuracy: 0.8693 - val_loss: 0.4247 - val_accuracy: 0.8498\n",
            "Epoch 529/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3287 - accuracy: 0.8716 - val_loss: 0.4182 - val_accuracy: 0.8512\n",
            "Epoch 530/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3345 - accuracy: 0.8696 - val_loss: 0.4227 - val_accuracy: 0.8483\n",
            "Epoch 531/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3312 - accuracy: 0.8684 - val_loss: 0.4247 - val_accuracy: 0.8487\n",
            "Epoch 532/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3297 - accuracy: 0.8707 - val_loss: 0.4173 - val_accuracy: 0.8484\n",
            "Epoch 533/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3309 - accuracy: 0.8717 - val_loss: 0.4170 - val_accuracy: 0.8508\n",
            "Epoch 534/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3322 - accuracy: 0.8703 - val_loss: 0.4235 - val_accuracy: 0.8485\n",
            "Epoch 535/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3346 - accuracy: 0.8688 - val_loss: 0.4053 - val_accuracy: 0.8534\n",
            "Epoch 536/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3323 - accuracy: 0.8705 - val_loss: 0.4174 - val_accuracy: 0.8496\n",
            "Epoch 537/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3317 - accuracy: 0.8706 - val_loss: 0.4142 - val_accuracy: 0.8501\n",
            "Epoch 538/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3349 - accuracy: 0.8673 - val_loss: 0.4217 - val_accuracy: 0.8511\n",
            "Epoch 539/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3307 - accuracy: 0.8704 - val_loss: 0.4155 - val_accuracy: 0.8509\n",
            "Epoch 540/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3325 - accuracy: 0.8714 - val_loss: 0.4112 - val_accuracy: 0.8526\n",
            "Epoch 541/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3294 - accuracy: 0.8704 - val_loss: 0.4179 - val_accuracy: 0.8536\n",
            "Epoch 542/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3319 - accuracy: 0.8699 - val_loss: 0.4169 - val_accuracy: 0.8503\n",
            "Epoch 543/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3313 - accuracy: 0.8695 - val_loss: 0.4183 - val_accuracy: 0.8468\n",
            "Epoch 544/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3294 - accuracy: 0.8709 - val_loss: 0.4166 - val_accuracy: 0.8478\n",
            "Epoch 545/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3302 - accuracy: 0.8710 - val_loss: 0.4198 - val_accuracy: 0.8497\n",
            "Epoch 546/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3273 - accuracy: 0.8732 - val_loss: 0.4195 - val_accuracy: 0.8520\n",
            "Epoch 547/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3299 - accuracy: 0.8700 - val_loss: 0.4144 - val_accuracy: 0.8528\n",
            "Epoch 548/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3301 - accuracy: 0.8714 - val_loss: 0.4182 - val_accuracy: 0.8476\n",
            "Epoch 549/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3324 - accuracy: 0.8701 - val_loss: 0.4157 - val_accuracy: 0.8510\n",
            "Epoch 550/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3297 - accuracy: 0.8703 - val_loss: 0.4227 - val_accuracy: 0.8483\n",
            "Epoch 551/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3259 - accuracy: 0.8723 - val_loss: 0.4338 - val_accuracy: 0.8473\n",
            "Epoch 552/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3290 - accuracy: 0.8716 - val_loss: 0.4189 - val_accuracy: 0.8490\n",
            "Epoch 553/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3310 - accuracy: 0.8704 - val_loss: 0.4213 - val_accuracy: 0.8477\n",
            "Epoch 554/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3296 - accuracy: 0.8709 - val_loss: 0.4219 - val_accuracy: 0.8493\n",
            "Epoch 555/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3305 - accuracy: 0.8712 - val_loss: 0.4159 - val_accuracy: 0.8491\n",
            "Epoch 556/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3291 - accuracy: 0.8715 - val_loss: 0.4191 - val_accuracy: 0.8523\n",
            "Epoch 557/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3304 - accuracy: 0.8690 - val_loss: 0.4260 - val_accuracy: 0.8511\n",
            "Epoch 558/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3297 - accuracy: 0.8714 - val_loss: 0.4196 - val_accuracy: 0.8529\n",
            "Epoch 559/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3279 - accuracy: 0.8715 - val_loss: 0.4178 - val_accuracy: 0.8514\n",
            "Epoch 560/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3250 - accuracy: 0.8742 - val_loss: 0.4190 - val_accuracy: 0.8518\n",
            "Epoch 561/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3277 - accuracy: 0.8716 - val_loss: 0.4263 - val_accuracy: 0.8496\n",
            "Epoch 562/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3289 - accuracy: 0.8705 - val_loss: 0.4158 - val_accuracy: 0.8511\n",
            "Epoch 563/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3274 - accuracy: 0.8713 - val_loss: 0.4242 - val_accuracy: 0.8497\n",
            "Epoch 564/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3294 - accuracy: 0.8719 - val_loss: 0.4211 - val_accuracy: 0.8537\n",
            "Epoch 565/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3335 - accuracy: 0.8699 - val_loss: 0.4192 - val_accuracy: 0.8512\n",
            "Epoch 566/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3271 - accuracy: 0.8736 - val_loss: 0.4218 - val_accuracy: 0.8487\n",
            "Epoch 567/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3279 - accuracy: 0.8709 - val_loss: 0.4290 - val_accuracy: 0.8471\n",
            "Epoch 568/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3317 - accuracy: 0.8699 - val_loss: 0.4111 - val_accuracy: 0.8496\n",
            "Epoch 569/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3275 - accuracy: 0.8719 - val_loss: 0.4170 - val_accuracy: 0.8487\n",
            "Epoch 570/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3260 - accuracy: 0.8740 - val_loss: 0.4214 - val_accuracy: 0.8509\n",
            "Epoch 571/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3290 - accuracy: 0.8720 - val_loss: 0.4190 - val_accuracy: 0.8486\n",
            "Epoch 572/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3326 - accuracy: 0.8718 - val_loss: 0.4278 - val_accuracy: 0.8464\n",
            "Epoch 573/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3289 - accuracy: 0.8713 - val_loss: 0.4234 - val_accuracy: 0.8472\n",
            "Epoch 574/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3270 - accuracy: 0.8714 - val_loss: 0.4224 - val_accuracy: 0.8485\n",
            "Epoch 575/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3241 - accuracy: 0.8740 - val_loss: 0.4271 - val_accuracy: 0.8484\n",
            "Epoch 576/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3289 - accuracy: 0.8714 - val_loss: 0.4093 - val_accuracy: 0.8509\n",
            "Epoch 577/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3278 - accuracy: 0.8723 - val_loss: 0.4196 - val_accuracy: 0.8512\n",
            "Epoch 578/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3258 - accuracy: 0.8715 - val_loss: 0.4240 - val_accuracy: 0.8457\n",
            "Epoch 579/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3269 - accuracy: 0.8725 - val_loss: 0.4181 - val_accuracy: 0.8515\n",
            "Epoch 580/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3306 - accuracy: 0.8710 - val_loss: 0.4202 - val_accuracy: 0.8483\n",
            "Epoch 581/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3299 - accuracy: 0.8705 - val_loss: 0.4237 - val_accuracy: 0.8497\n",
            "Epoch 582/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3300 - accuracy: 0.8696 - val_loss: 0.4195 - val_accuracy: 0.8501\n",
            "Epoch 583/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3234 - accuracy: 0.8729 - val_loss: 0.4212 - val_accuracy: 0.8515\n",
            "Epoch 584/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3239 - accuracy: 0.8734 - val_loss: 0.4244 - val_accuracy: 0.8512\n",
            "Epoch 585/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3235 - accuracy: 0.8733 - val_loss: 0.4212 - val_accuracy: 0.8504\n",
            "Epoch 586/900\n",
            "93/93 [==============================] - 3s 29ms/step - loss: 0.3275 - accuracy: 0.8724 - val_loss: 0.4198 - val_accuracy: 0.8499\n",
            "Epoch 587/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3240 - accuracy: 0.8748 - val_loss: 0.4175 - val_accuracy: 0.8514\n",
            "Epoch 588/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3261 - accuracy: 0.8737 - val_loss: 0.4220 - val_accuracy: 0.8493\n",
            "Epoch 589/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3259 - accuracy: 0.8724 - val_loss: 0.4207 - val_accuracy: 0.8530\n",
            "Epoch 590/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3247 - accuracy: 0.8729 - val_loss: 0.4183 - val_accuracy: 0.8509\n",
            "Epoch 591/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3225 - accuracy: 0.8748 - val_loss: 0.4219 - val_accuracy: 0.8493\n",
            "Epoch 592/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3275 - accuracy: 0.8720 - val_loss: 0.4178 - val_accuracy: 0.8516\n",
            "Epoch 593/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3268 - accuracy: 0.8732 - val_loss: 0.4128 - val_accuracy: 0.8527\n",
            "Epoch 594/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3260 - accuracy: 0.8732 - val_loss: 0.4166 - val_accuracy: 0.8501\n",
            "Epoch 595/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3237 - accuracy: 0.8714 - val_loss: 0.4188 - val_accuracy: 0.8491\n",
            "Epoch 596/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3270 - accuracy: 0.8723 - val_loss: 0.4218 - val_accuracy: 0.8501\n",
            "Epoch 597/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3233 - accuracy: 0.8738 - val_loss: 0.4215 - val_accuracy: 0.8487\n",
            "Epoch 598/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3279 - accuracy: 0.8724 - val_loss: 0.4186 - val_accuracy: 0.8492\n",
            "Epoch 599/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3277 - accuracy: 0.8721 - val_loss: 0.4148 - val_accuracy: 0.8511\n",
            "Epoch 600/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3232 - accuracy: 0.8752 - val_loss: 0.4194 - val_accuracy: 0.8472\n",
            "Epoch 601/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3220 - accuracy: 0.8736 - val_loss: 0.4162 - val_accuracy: 0.8515\n",
            "Epoch 602/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3261 - accuracy: 0.8716 - val_loss: 0.4165 - val_accuracy: 0.8474\n",
            "Epoch 603/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3263 - accuracy: 0.8734 - val_loss: 0.4165 - val_accuracy: 0.8521\n",
            "Epoch 604/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3221 - accuracy: 0.8750 - val_loss: 0.4231 - val_accuracy: 0.8493\n",
            "Epoch 605/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3236 - accuracy: 0.8740 - val_loss: 0.4233 - val_accuracy: 0.8489\n",
            "Epoch 606/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3228 - accuracy: 0.8733 - val_loss: 0.4261 - val_accuracy: 0.8493\n",
            "Epoch 607/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3231 - accuracy: 0.8746 - val_loss: 0.4252 - val_accuracy: 0.8522\n",
            "Epoch 608/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3207 - accuracy: 0.8763 - val_loss: 0.4188 - val_accuracy: 0.8511\n",
            "Epoch 609/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3252 - accuracy: 0.8740 - val_loss: 0.4155 - val_accuracy: 0.8501\n",
            "Epoch 610/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3262 - accuracy: 0.8715 - val_loss: 0.4194 - val_accuracy: 0.8471\n",
            "Epoch 611/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3218 - accuracy: 0.8750 - val_loss: 0.4232 - val_accuracy: 0.8495\n",
            "Epoch 612/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3245 - accuracy: 0.8734 - val_loss: 0.4155 - val_accuracy: 0.8520\n",
            "Epoch 613/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3252 - accuracy: 0.8739 - val_loss: 0.4178 - val_accuracy: 0.8520\n",
            "Epoch 614/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3273 - accuracy: 0.8740 - val_loss: 0.4177 - val_accuracy: 0.8537\n",
            "Epoch 615/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3243 - accuracy: 0.8732 - val_loss: 0.4131 - val_accuracy: 0.8515\n",
            "Epoch 616/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3258 - accuracy: 0.8727 - val_loss: 0.4118 - val_accuracy: 0.8516\n",
            "Epoch 617/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3234 - accuracy: 0.8744 - val_loss: 0.4164 - val_accuracy: 0.8517\n",
            "Epoch 618/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3235 - accuracy: 0.8728 - val_loss: 0.4182 - val_accuracy: 0.8505\n",
            "Epoch 619/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3203 - accuracy: 0.8757 - val_loss: 0.4173 - val_accuracy: 0.8487\n",
            "Epoch 620/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3232 - accuracy: 0.8750 - val_loss: 0.4170 - val_accuracy: 0.8487\n",
            "Epoch 621/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3257 - accuracy: 0.8713 - val_loss: 0.4169 - val_accuracy: 0.8498\n",
            "Epoch 622/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3230 - accuracy: 0.8735 - val_loss: 0.4195 - val_accuracy: 0.8484\n",
            "Epoch 623/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3243 - accuracy: 0.8733 - val_loss: 0.4235 - val_accuracy: 0.8512\n",
            "Epoch 624/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3200 - accuracy: 0.8758 - val_loss: 0.4145 - val_accuracy: 0.8526\n",
            "Epoch 625/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3205 - accuracy: 0.8767 - val_loss: 0.4142 - val_accuracy: 0.8511\n",
            "Epoch 626/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3226 - accuracy: 0.8739 - val_loss: 0.4204 - val_accuracy: 0.8496\n",
            "Epoch 627/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3279 - accuracy: 0.8726 - val_loss: 0.4140 - val_accuracy: 0.8508\n",
            "Epoch 628/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3218 - accuracy: 0.8749 - val_loss: 0.4193 - val_accuracy: 0.8486\n",
            "Epoch 629/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3246 - accuracy: 0.8724 - val_loss: 0.4161 - val_accuracy: 0.8535\n",
            "Epoch 630/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3239 - accuracy: 0.8727 - val_loss: 0.4143 - val_accuracy: 0.8537\n",
            "Epoch 631/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3183 - accuracy: 0.8757 - val_loss: 0.4257 - val_accuracy: 0.8479\n",
            "Epoch 632/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3193 - accuracy: 0.8742 - val_loss: 0.4281 - val_accuracy: 0.8476\n",
            "Epoch 633/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3224 - accuracy: 0.8737 - val_loss: 0.4118 - val_accuracy: 0.8493\n",
            "Epoch 634/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3206 - accuracy: 0.8757 - val_loss: 0.4210 - val_accuracy: 0.8478\n",
            "Epoch 635/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3212 - accuracy: 0.8743 - val_loss: 0.4155 - val_accuracy: 0.8518\n",
            "Epoch 636/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3210 - accuracy: 0.8754 - val_loss: 0.4170 - val_accuracy: 0.8510\n",
            "Epoch 637/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3204 - accuracy: 0.8747 - val_loss: 0.4243 - val_accuracy: 0.8491\n",
            "Epoch 638/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3162 - accuracy: 0.8773 - val_loss: 0.4247 - val_accuracy: 0.8490\n",
            "Epoch 639/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3226 - accuracy: 0.8752 - val_loss: 0.4221 - val_accuracy: 0.8539\n",
            "Epoch 640/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3214 - accuracy: 0.8753 - val_loss: 0.4159 - val_accuracy: 0.8505\n",
            "Epoch 641/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3177 - accuracy: 0.8750 - val_loss: 0.4280 - val_accuracy: 0.8474\n",
            "Epoch 642/900\n",
            "93/93 [==============================] - 3s 38ms/step - loss: 0.3176 - accuracy: 0.8752 - val_loss: 0.4183 - val_accuracy: 0.8520\n",
            "Epoch 643/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3199 - accuracy: 0.8747 - val_loss: 0.4211 - val_accuracy: 0.8527\n",
            "Epoch 644/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3227 - accuracy: 0.8755 - val_loss: 0.4067 - val_accuracy: 0.8530\n",
            "Epoch 645/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3269 - accuracy: 0.8717 - val_loss: 0.4169 - val_accuracy: 0.8539\n",
            "Epoch 646/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3219 - accuracy: 0.8734 - val_loss: 0.4189 - val_accuracy: 0.8515\n",
            "Epoch 647/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3250 - accuracy: 0.8728 - val_loss: 0.4161 - val_accuracy: 0.8534\n",
            "Epoch 648/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3191 - accuracy: 0.8746 - val_loss: 0.4194 - val_accuracy: 0.8499\n",
            "Epoch 649/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3175 - accuracy: 0.8757 - val_loss: 0.4218 - val_accuracy: 0.8481\n",
            "Epoch 650/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3217 - accuracy: 0.8738 - val_loss: 0.4189 - val_accuracy: 0.8533\n",
            "Epoch 651/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3169 - accuracy: 0.8770 - val_loss: 0.4210 - val_accuracy: 0.8487\n",
            "Epoch 652/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3218 - accuracy: 0.8749 - val_loss: 0.4280 - val_accuracy: 0.8489\n",
            "Epoch 653/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3203 - accuracy: 0.8756 - val_loss: 0.4198 - val_accuracy: 0.8508\n",
            "Epoch 654/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3182 - accuracy: 0.8751 - val_loss: 0.4179 - val_accuracy: 0.8509\n",
            "Epoch 655/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3170 - accuracy: 0.8773 - val_loss: 0.4170 - val_accuracy: 0.8520\n",
            "Epoch 656/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3195 - accuracy: 0.8755 - val_loss: 0.4202 - val_accuracy: 0.8515\n",
            "Epoch 657/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3204 - accuracy: 0.8747 - val_loss: 0.4148 - val_accuracy: 0.8516\n",
            "Epoch 658/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3204 - accuracy: 0.8765 - val_loss: 0.4209 - val_accuracy: 0.8498\n",
            "Epoch 659/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3162 - accuracy: 0.8764 - val_loss: 0.4215 - val_accuracy: 0.8501\n",
            "Epoch 660/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3159 - accuracy: 0.8771 - val_loss: 0.4259 - val_accuracy: 0.8514\n",
            "Epoch 661/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3186 - accuracy: 0.8749 - val_loss: 0.4299 - val_accuracy: 0.8515\n",
            "Epoch 662/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3195 - accuracy: 0.8747 - val_loss: 0.4163 - val_accuracy: 0.8524\n",
            "Epoch 663/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3213 - accuracy: 0.8751 - val_loss: 0.4257 - val_accuracy: 0.8492\n",
            "Epoch 664/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3147 - accuracy: 0.8786 - val_loss: 0.4190 - val_accuracy: 0.8470\n",
            "Epoch 665/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3170 - accuracy: 0.8775 - val_loss: 0.4169 - val_accuracy: 0.8497\n",
            "Epoch 666/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3149 - accuracy: 0.8774 - val_loss: 0.4292 - val_accuracy: 0.8506\n",
            "Epoch 667/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3202 - accuracy: 0.8764 - val_loss: 0.4127 - val_accuracy: 0.8520\n",
            "Epoch 668/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3122 - accuracy: 0.8784 - val_loss: 0.4274 - val_accuracy: 0.8504\n",
            "Epoch 669/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3176 - accuracy: 0.8755 - val_loss: 0.4232 - val_accuracy: 0.8521\n",
            "Epoch 670/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3197 - accuracy: 0.8744 - val_loss: 0.4361 - val_accuracy: 0.8501\n",
            "Epoch 671/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3179 - accuracy: 0.8760 - val_loss: 0.4220 - val_accuracy: 0.8496\n",
            "Epoch 672/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3169 - accuracy: 0.8759 - val_loss: 0.4192 - val_accuracy: 0.8512\n",
            "Epoch 673/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3175 - accuracy: 0.8756 - val_loss: 0.4306 - val_accuracy: 0.8493\n",
            "Epoch 674/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3192 - accuracy: 0.8745 - val_loss: 0.4285 - val_accuracy: 0.8511\n",
            "Epoch 675/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3171 - accuracy: 0.8761 - val_loss: 0.4190 - val_accuracy: 0.8548\n",
            "Epoch 676/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3135 - accuracy: 0.8783 - val_loss: 0.4220 - val_accuracy: 0.8521\n",
            "Epoch 677/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3171 - accuracy: 0.8765 - val_loss: 0.4150 - val_accuracy: 0.8536\n",
            "Epoch 678/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3132 - accuracy: 0.8777 - val_loss: 0.4214 - val_accuracy: 0.8512\n",
            "Epoch 679/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3139 - accuracy: 0.8778 - val_loss: 0.4208 - val_accuracy: 0.8506\n",
            "Epoch 680/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3156 - accuracy: 0.8775 - val_loss: 0.4184 - val_accuracy: 0.8522\n",
            "Epoch 681/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3133 - accuracy: 0.8779 - val_loss: 0.4195 - val_accuracy: 0.8518\n",
            "Epoch 682/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3150 - accuracy: 0.8762 - val_loss: 0.4175 - val_accuracy: 0.8514\n",
            "Epoch 683/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3204 - accuracy: 0.8758 - val_loss: 0.4149 - val_accuracy: 0.8516\n",
            "Epoch 684/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3154 - accuracy: 0.8784 - val_loss: 0.4147 - val_accuracy: 0.8540\n",
            "Epoch 685/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3176 - accuracy: 0.8768 - val_loss: 0.4113 - val_accuracy: 0.8546\n",
            "Epoch 686/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3152 - accuracy: 0.8767 - val_loss: 0.4181 - val_accuracy: 0.8528\n",
            "Epoch 687/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3186 - accuracy: 0.8763 - val_loss: 0.4138 - val_accuracy: 0.8536\n",
            "Epoch 688/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3138 - accuracy: 0.8775 - val_loss: 0.4151 - val_accuracy: 0.8518\n",
            "Epoch 689/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3200 - accuracy: 0.8750 - val_loss: 0.4163 - val_accuracy: 0.8536\n",
            "Epoch 690/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3172 - accuracy: 0.8759 - val_loss: 0.4173 - val_accuracy: 0.8518\n",
            "Epoch 691/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3164 - accuracy: 0.8754 - val_loss: 0.4161 - val_accuracy: 0.8526\n",
            "Epoch 692/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3181 - accuracy: 0.8753 - val_loss: 0.4158 - val_accuracy: 0.8505\n",
            "Epoch 693/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3180 - accuracy: 0.8750 - val_loss: 0.4168 - val_accuracy: 0.8545\n",
            "Epoch 694/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3178 - accuracy: 0.8759 - val_loss: 0.4195 - val_accuracy: 0.8531\n",
            "Epoch 695/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3219 - accuracy: 0.8739 - val_loss: 0.4146 - val_accuracy: 0.8518\n",
            "Epoch 696/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3154 - accuracy: 0.8774 - val_loss: 0.4152 - val_accuracy: 0.8518\n",
            "Epoch 697/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3147 - accuracy: 0.8761 - val_loss: 0.4146 - val_accuracy: 0.8523\n",
            "Epoch 698/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3146 - accuracy: 0.8763 - val_loss: 0.4161 - val_accuracy: 0.8549\n",
            "Epoch 699/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3166 - accuracy: 0.8783 - val_loss: 0.4118 - val_accuracy: 0.8552\n",
            "Epoch 700/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3170 - accuracy: 0.8774 - val_loss: 0.4134 - val_accuracy: 0.8554\n",
            "Epoch 701/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3109 - accuracy: 0.8799 - val_loss: 0.4137 - val_accuracy: 0.8552\n",
            "Epoch 702/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3140 - accuracy: 0.8758 - val_loss: 0.4228 - val_accuracy: 0.8518\n",
            "Epoch 703/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3189 - accuracy: 0.8760 - val_loss: 0.4162 - val_accuracy: 0.8530\n",
            "Epoch 704/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3151 - accuracy: 0.8774 - val_loss: 0.4208 - val_accuracy: 0.8524\n",
            "Epoch 705/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3132 - accuracy: 0.8784 - val_loss: 0.4213 - val_accuracy: 0.8517\n",
            "Epoch 706/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3161 - accuracy: 0.8773 - val_loss: 0.4175 - val_accuracy: 0.8539\n",
            "Epoch 707/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3141 - accuracy: 0.8795 - val_loss: 0.4251 - val_accuracy: 0.8510\n",
            "Epoch 708/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3171 - accuracy: 0.8776 - val_loss: 0.4180 - val_accuracy: 0.8530\n",
            "Epoch 709/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3122 - accuracy: 0.8794 - val_loss: 0.4206 - val_accuracy: 0.8535\n",
            "Epoch 710/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3067 - accuracy: 0.8807 - val_loss: 0.4143 - val_accuracy: 0.8534\n",
            "Epoch 711/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3132 - accuracy: 0.8783 - val_loss: 0.4175 - val_accuracy: 0.8546\n",
            "Epoch 712/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3141 - accuracy: 0.8778 - val_loss: 0.4193 - val_accuracy: 0.8499\n",
            "Epoch 713/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3146 - accuracy: 0.8767 - val_loss: 0.4162 - val_accuracy: 0.8521\n",
            "Epoch 714/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3119 - accuracy: 0.8787 - val_loss: 0.4207 - val_accuracy: 0.8548\n",
            "Epoch 715/900\n",
            "93/93 [==============================] - 3s 30ms/step - loss: 0.3166 - accuracy: 0.8770 - val_loss: 0.4203 - val_accuracy: 0.8508\n",
            "Epoch 716/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3159 - accuracy: 0.8755 - val_loss: 0.4147 - val_accuracy: 0.8543\n",
            "Epoch 717/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3123 - accuracy: 0.8782 - val_loss: 0.4154 - val_accuracy: 0.8518\n",
            "Epoch 718/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3143 - accuracy: 0.8773 - val_loss: 0.4202 - val_accuracy: 0.8521\n",
            "Epoch 719/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3111 - accuracy: 0.8786 - val_loss: 0.4173 - val_accuracy: 0.8529\n",
            "Epoch 720/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3126 - accuracy: 0.8776 - val_loss: 0.4214 - val_accuracy: 0.8487\n",
            "Epoch 721/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3146 - accuracy: 0.8762 - val_loss: 0.4233 - val_accuracy: 0.8509\n",
            "Epoch 722/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3104 - accuracy: 0.8799 - val_loss: 0.4193 - val_accuracy: 0.8516\n",
            "Epoch 723/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3150 - accuracy: 0.8764 - val_loss: 0.4244 - val_accuracy: 0.8514\n",
            "Epoch 724/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3154 - accuracy: 0.8776 - val_loss: 0.4225 - val_accuracy: 0.8522\n",
            "Epoch 725/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3147 - accuracy: 0.8765 - val_loss: 0.4249 - val_accuracy: 0.8522\n",
            "Epoch 726/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3141 - accuracy: 0.8775 - val_loss: 0.4165 - val_accuracy: 0.8537\n",
            "Epoch 727/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3095 - accuracy: 0.8778 - val_loss: 0.4182 - val_accuracy: 0.8529\n",
            "Epoch 728/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3158 - accuracy: 0.8761 - val_loss: 0.4195 - val_accuracy: 0.8502\n",
            "Epoch 729/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3134 - accuracy: 0.8767 - val_loss: 0.4199 - val_accuracy: 0.8537\n",
            "Epoch 730/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3101 - accuracy: 0.8771 - val_loss: 0.4166 - val_accuracy: 0.8508\n",
            "Epoch 731/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3130 - accuracy: 0.8782 - val_loss: 0.4185 - val_accuracy: 0.8541\n",
            "Epoch 732/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3104 - accuracy: 0.8793 - val_loss: 0.4188 - val_accuracy: 0.8521\n",
            "Epoch 733/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3111 - accuracy: 0.8768 - val_loss: 0.4179 - val_accuracy: 0.8531\n",
            "Epoch 734/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3114 - accuracy: 0.8782 - val_loss: 0.4235 - val_accuracy: 0.8485\n",
            "Epoch 735/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3098 - accuracy: 0.8776 - val_loss: 0.4261 - val_accuracy: 0.8541\n",
            "Epoch 736/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3128 - accuracy: 0.8778 - val_loss: 0.4176 - val_accuracy: 0.8504\n",
            "Epoch 737/900\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3121 - accuracy: 0.8781 - val_loss: 0.4176 - val_accuracy: 0.8537\n",
            "Epoch 738/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3126 - accuracy: 0.8785 - val_loss: 0.4111 - val_accuracy: 0.8512\n",
            "Epoch 739/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3096 - accuracy: 0.8796 - val_loss: 0.4222 - val_accuracy: 0.8510\n",
            "Epoch 740/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3125 - accuracy: 0.8778 - val_loss: 0.4198 - val_accuracy: 0.8533\n",
            "Epoch 741/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3132 - accuracy: 0.8779 - val_loss: 0.4211 - val_accuracy: 0.8533\n",
            "Epoch 742/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3135 - accuracy: 0.8758 - val_loss: 0.4214 - val_accuracy: 0.8520\n",
            "Epoch 743/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3098 - accuracy: 0.8809 - val_loss: 0.4293 - val_accuracy: 0.8497\n",
            "Epoch 744/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3105 - accuracy: 0.8801 - val_loss: 0.4274 - val_accuracy: 0.8493\n",
            "Epoch 745/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3151 - accuracy: 0.8791 - val_loss: 0.4152 - val_accuracy: 0.8518\n",
            "Epoch 746/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3131 - accuracy: 0.8780 - val_loss: 0.4185 - val_accuracy: 0.8517\n",
            "Epoch 747/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3119 - accuracy: 0.8787 - val_loss: 0.4112 - val_accuracy: 0.8503\n",
            "Epoch 748/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3109 - accuracy: 0.8801 - val_loss: 0.4230 - val_accuracy: 0.8537\n",
            "Epoch 749/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3145 - accuracy: 0.8774 - val_loss: 0.4231 - val_accuracy: 0.8547\n",
            "Epoch 750/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3134 - accuracy: 0.8785 - val_loss: 0.4221 - val_accuracy: 0.8489\n",
            "Epoch 751/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3134 - accuracy: 0.8780 - val_loss: 0.4145 - val_accuracy: 0.8530\n",
            "Epoch 752/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3152 - accuracy: 0.8779 - val_loss: 0.4203 - val_accuracy: 0.8545\n",
            "Epoch 753/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3101 - accuracy: 0.8779 - val_loss: 0.4167 - val_accuracy: 0.8543\n",
            "Epoch 754/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3144 - accuracy: 0.8778 - val_loss: 0.4237 - val_accuracy: 0.8517\n",
            "Epoch 755/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3067 - accuracy: 0.8802 - val_loss: 0.4264 - val_accuracy: 0.8508\n",
            "Epoch 756/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3102 - accuracy: 0.8782 - val_loss: 0.4268 - val_accuracy: 0.8549\n",
            "Epoch 757/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3107 - accuracy: 0.8781 - val_loss: 0.4148 - val_accuracy: 0.8536\n",
            "Epoch 758/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3097 - accuracy: 0.8803 - val_loss: 0.4257 - val_accuracy: 0.8509\n",
            "Epoch 759/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3111 - accuracy: 0.8778 - val_loss: 0.4228 - val_accuracy: 0.8528\n",
            "Epoch 760/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3083 - accuracy: 0.8793 - val_loss: 0.4263 - val_accuracy: 0.8523\n",
            "Epoch 761/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3143 - accuracy: 0.8779 - val_loss: 0.4167 - val_accuracy: 0.8536\n",
            "Epoch 762/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3097 - accuracy: 0.8793 - val_loss: 0.4251 - val_accuracy: 0.8534\n",
            "Epoch 763/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3052 - accuracy: 0.8816 - val_loss: 0.4203 - val_accuracy: 0.8531\n",
            "Epoch 764/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3102 - accuracy: 0.8800 - val_loss: 0.4240 - val_accuracy: 0.8549\n",
            "Epoch 765/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3112 - accuracy: 0.8794 - val_loss: 0.4190 - val_accuracy: 0.8539\n",
            "Epoch 766/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3115 - accuracy: 0.8788 - val_loss: 0.4143 - val_accuracy: 0.8521\n",
            "Epoch 767/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3100 - accuracy: 0.8793 - val_loss: 0.4158 - val_accuracy: 0.8529\n",
            "Epoch 768/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3087 - accuracy: 0.8798 - val_loss: 0.4206 - val_accuracy: 0.8533\n",
            "Epoch 769/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3109 - accuracy: 0.8773 - val_loss: 0.4174 - val_accuracy: 0.8562\n",
            "Epoch 770/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3053 - accuracy: 0.8804 - val_loss: 0.4235 - val_accuracy: 0.8547\n",
            "Epoch 771/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3072 - accuracy: 0.8796 - val_loss: 0.4266 - val_accuracy: 0.8533\n",
            "Epoch 772/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3117 - accuracy: 0.8788 - val_loss: 0.4290 - val_accuracy: 0.8526\n",
            "Epoch 773/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3114 - accuracy: 0.8774 - val_loss: 0.4180 - val_accuracy: 0.8531\n",
            "Epoch 774/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3106 - accuracy: 0.8797 - val_loss: 0.4185 - val_accuracy: 0.8526\n",
            "Epoch 775/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3098 - accuracy: 0.8799 - val_loss: 0.4217 - val_accuracy: 0.8518\n",
            "Epoch 776/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3098 - accuracy: 0.8795 - val_loss: 0.4154 - val_accuracy: 0.8546\n",
            "Epoch 777/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3072 - accuracy: 0.8788 - val_loss: 0.4225 - val_accuracy: 0.8551\n",
            "Epoch 778/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3078 - accuracy: 0.8790 - val_loss: 0.4189 - val_accuracy: 0.8530\n",
            "Epoch 779/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3098 - accuracy: 0.8798 - val_loss: 0.4122 - val_accuracy: 0.8541\n",
            "Epoch 780/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3081 - accuracy: 0.8814 - val_loss: 0.4209 - val_accuracy: 0.8527\n",
            "Epoch 781/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3064 - accuracy: 0.8814 - val_loss: 0.4207 - val_accuracy: 0.8523\n",
            "Epoch 782/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3086 - accuracy: 0.8813 - val_loss: 0.4174 - val_accuracy: 0.8536\n",
            "Epoch 783/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3123 - accuracy: 0.8797 - val_loss: 0.4109 - val_accuracy: 0.8529\n",
            "Epoch 784/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3070 - accuracy: 0.8799 - val_loss: 0.4175 - val_accuracy: 0.8546\n",
            "Epoch 785/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3100 - accuracy: 0.8794 - val_loss: 0.4195 - val_accuracy: 0.8555\n",
            "Epoch 786/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3069 - accuracy: 0.8808 - val_loss: 0.4210 - val_accuracy: 0.8521\n",
            "Epoch 787/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3088 - accuracy: 0.8817 - val_loss: 0.4222 - val_accuracy: 0.8533\n",
            "Epoch 788/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3072 - accuracy: 0.8797 - val_loss: 0.4145 - val_accuracy: 0.8556\n",
            "Epoch 789/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3089 - accuracy: 0.8788 - val_loss: 0.4148 - val_accuracy: 0.8559\n",
            "Epoch 790/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3091 - accuracy: 0.8796 - val_loss: 0.4117 - val_accuracy: 0.8547\n",
            "Epoch 791/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3072 - accuracy: 0.8798 - val_loss: 0.4102 - val_accuracy: 0.8554\n",
            "Epoch 792/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3066 - accuracy: 0.8820 - val_loss: 0.4177 - val_accuracy: 0.8531\n",
            "Epoch 793/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3070 - accuracy: 0.8796 - val_loss: 0.4147 - val_accuracy: 0.8539\n",
            "Epoch 794/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3068 - accuracy: 0.8807 - val_loss: 0.4280 - val_accuracy: 0.8527\n",
            "Epoch 795/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3093 - accuracy: 0.8778 - val_loss: 0.4202 - val_accuracy: 0.8514\n",
            "Epoch 796/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3067 - accuracy: 0.8800 - val_loss: 0.4306 - val_accuracy: 0.8511\n",
            "Epoch 797/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3112 - accuracy: 0.8798 - val_loss: 0.4148 - val_accuracy: 0.8543\n",
            "Epoch 798/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3061 - accuracy: 0.8825 - val_loss: 0.4214 - val_accuracy: 0.8521\n",
            "Epoch 799/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3071 - accuracy: 0.8800 - val_loss: 0.4230 - val_accuracy: 0.8522\n",
            "Epoch 800/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3087 - accuracy: 0.8802 - val_loss: 0.4213 - val_accuracy: 0.8516\n",
            "Epoch 801/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3085 - accuracy: 0.8785 - val_loss: 0.4233 - val_accuracy: 0.8496\n",
            "Epoch 802/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3144 - accuracy: 0.8775 - val_loss: 0.4179 - val_accuracy: 0.8528\n",
            "Epoch 803/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3045 - accuracy: 0.8811 - val_loss: 0.4174 - val_accuracy: 0.8555\n",
            "Epoch 804/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3090 - accuracy: 0.8792 - val_loss: 0.4199 - val_accuracy: 0.8542\n",
            "Epoch 805/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3029 - accuracy: 0.8814 - val_loss: 0.4273 - val_accuracy: 0.8548\n",
            "Epoch 806/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3093 - accuracy: 0.8810 - val_loss: 0.4211 - val_accuracy: 0.8554\n",
            "Epoch 807/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3001 - accuracy: 0.8834 - val_loss: 0.4266 - val_accuracy: 0.8528\n",
            "Epoch 808/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3093 - accuracy: 0.8792 - val_loss: 0.4243 - val_accuracy: 0.8535\n",
            "Epoch 809/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3073 - accuracy: 0.8803 - val_loss: 0.4222 - val_accuracy: 0.8521\n",
            "Epoch 810/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3086 - accuracy: 0.8796 - val_loss: 0.4295 - val_accuracy: 0.8518\n",
            "Epoch 811/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3080 - accuracy: 0.8808 - val_loss: 0.4201 - val_accuracy: 0.8533\n",
            "Epoch 812/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3095 - accuracy: 0.8784 - val_loss: 0.4108 - val_accuracy: 0.8565\n",
            "Epoch 813/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3019 - accuracy: 0.8825 - val_loss: 0.4181 - val_accuracy: 0.8534\n",
            "Epoch 814/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3057 - accuracy: 0.8806 - val_loss: 0.4212 - val_accuracy: 0.8527\n",
            "Epoch 815/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3065 - accuracy: 0.8803 - val_loss: 0.4150 - val_accuracy: 0.8559\n",
            "Epoch 816/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3077 - accuracy: 0.8813 - val_loss: 0.4248 - val_accuracy: 0.8530\n",
            "Epoch 817/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3029 - accuracy: 0.8813 - val_loss: 0.4224 - val_accuracy: 0.8543\n",
            "Epoch 818/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3044 - accuracy: 0.8833 - val_loss: 0.4167 - val_accuracy: 0.8547\n",
            "Epoch 819/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3101 - accuracy: 0.8804 - val_loss: 0.4125 - val_accuracy: 0.8548\n",
            "Epoch 820/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3092 - accuracy: 0.8791 - val_loss: 0.4152 - val_accuracy: 0.8551\n",
            "Epoch 821/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3069 - accuracy: 0.8793 - val_loss: 0.4130 - val_accuracy: 0.8534\n",
            "Epoch 822/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3057 - accuracy: 0.8812 - val_loss: 0.4217 - val_accuracy: 0.8540\n",
            "Epoch 823/900\n",
            "93/93 [==============================] - 3s 37ms/step - loss: 0.3099 - accuracy: 0.8793 - val_loss: 0.4228 - val_accuracy: 0.8512\n",
            "Epoch 824/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3079 - accuracy: 0.8802 - val_loss: 0.4158 - val_accuracy: 0.8552\n",
            "Epoch 825/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3068 - accuracy: 0.8805 - val_loss: 0.4222 - val_accuracy: 0.8520\n",
            "Epoch 826/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3027 - accuracy: 0.8826 - val_loss: 0.4201 - val_accuracy: 0.8558\n",
            "Epoch 827/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3057 - accuracy: 0.8811 - val_loss: 0.4219 - val_accuracy: 0.8524\n",
            "Epoch 828/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3024 - accuracy: 0.8825 - val_loss: 0.4271 - val_accuracy: 0.8521\n",
            "Epoch 829/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3041 - accuracy: 0.8820 - val_loss: 0.4245 - val_accuracy: 0.8512\n",
            "Epoch 830/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3083 - accuracy: 0.8801 - val_loss: 0.4253 - val_accuracy: 0.8526\n",
            "Epoch 831/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3067 - accuracy: 0.8813 - val_loss: 0.4151 - val_accuracy: 0.8552\n",
            "Epoch 832/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3065 - accuracy: 0.8814 - val_loss: 0.4158 - val_accuracy: 0.8529\n",
            "Epoch 833/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3041 - accuracy: 0.8821 - val_loss: 0.4212 - val_accuracy: 0.8543\n",
            "Epoch 834/900\n",
            "93/93 [==============================] - 7s 70ms/step - loss: 0.3045 - accuracy: 0.8822 - val_loss: 0.4189 - val_accuracy: 0.8542\n",
            "Epoch 835/900\n",
            "93/93 [==============================] - 5s 50ms/step - loss: 0.3071 - accuracy: 0.8818 - val_loss: 0.4206 - val_accuracy: 0.8535\n",
            "Epoch 836/900\n",
            "93/93 [==============================] - 4s 48ms/step - loss: 0.3060 - accuracy: 0.8809 - val_loss: 0.4314 - val_accuracy: 0.8518\n",
            "Epoch 837/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3022 - accuracy: 0.8824 - val_loss: 0.4138 - val_accuracy: 0.8531\n",
            "Epoch 838/900\n",
            "93/93 [==============================] - 3s 34ms/step - loss: 0.3046 - accuracy: 0.8809 - val_loss: 0.4194 - val_accuracy: 0.8498\n",
            "Epoch 839/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3047 - accuracy: 0.8799 - val_loss: 0.4232 - val_accuracy: 0.8529\n",
            "Epoch 840/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3049 - accuracy: 0.8804 - val_loss: 0.4289 - val_accuracy: 0.8526\n",
            "Epoch 841/900\n",
            "93/93 [==============================] - 4s 39ms/step - loss: 0.3043 - accuracy: 0.8813 - val_loss: 0.4171 - val_accuracy: 0.8553\n",
            "Epoch 842/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3006 - accuracy: 0.8833 - val_loss: 0.4223 - val_accuracy: 0.8518\n",
            "Epoch 843/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3077 - accuracy: 0.8810 - val_loss: 0.4138 - val_accuracy: 0.8542\n",
            "Epoch 844/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3083 - accuracy: 0.8793 - val_loss: 0.4242 - val_accuracy: 0.8546\n",
            "Epoch 845/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3059 - accuracy: 0.8799 - val_loss: 0.4197 - val_accuracy: 0.8535\n",
            "Epoch 846/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3039 - accuracy: 0.8828 - val_loss: 0.4188 - val_accuracy: 0.8565\n",
            "Epoch 847/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3025 - accuracy: 0.8814 - val_loss: 0.4256 - val_accuracy: 0.8504\n",
            "Epoch 848/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3064 - accuracy: 0.8806 - val_loss: 0.4173 - val_accuracy: 0.8537\n",
            "Epoch 849/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3060 - accuracy: 0.8818 - val_loss: 0.4249 - val_accuracy: 0.8514\n",
            "Epoch 850/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3004 - accuracy: 0.8830 - val_loss: 0.4264 - val_accuracy: 0.8527\n",
            "Epoch 851/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3035 - accuracy: 0.8811 - val_loss: 0.4238 - val_accuracy: 0.8539\n",
            "Epoch 852/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3077 - accuracy: 0.8793 - val_loss: 0.4144 - val_accuracy: 0.8534\n",
            "Epoch 853/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3020 - accuracy: 0.8853 - val_loss: 0.4197 - val_accuracy: 0.8535\n",
            "Epoch 854/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3076 - accuracy: 0.8807 - val_loss: 0.4159 - val_accuracy: 0.8547\n",
            "Epoch 855/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3080 - accuracy: 0.8789 - val_loss: 0.4167 - val_accuracy: 0.8554\n",
            "Epoch 856/900\n",
            "93/93 [==============================] - 4s 42ms/step - loss: 0.3015 - accuracy: 0.8823 - val_loss: 0.4230 - val_accuracy: 0.8534\n",
            "Epoch 857/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3031 - accuracy: 0.8821 - val_loss: 0.4109 - val_accuracy: 0.8576\n",
            "Epoch 858/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3003 - accuracy: 0.8827 - val_loss: 0.4204 - val_accuracy: 0.8541\n",
            "Epoch 859/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3034 - accuracy: 0.8816 - val_loss: 0.4232 - val_accuracy: 0.8548\n",
            "Epoch 860/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3045 - accuracy: 0.8816 - val_loss: 0.4202 - val_accuracy: 0.8576\n",
            "Epoch 861/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3038 - accuracy: 0.8822 - val_loss: 0.4241 - val_accuracy: 0.8568\n",
            "Epoch 862/900\n",
            "93/93 [==============================] - 3s 36ms/step - loss: 0.3065 - accuracy: 0.8800 - val_loss: 0.4239 - val_accuracy: 0.8542\n",
            "Epoch 863/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3043 - accuracy: 0.8815 - val_loss: 0.4166 - val_accuracy: 0.8574\n",
            "Epoch 864/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3058 - accuracy: 0.8805 - val_loss: 0.4177 - val_accuracy: 0.8548\n",
            "Epoch 865/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.2990 - accuracy: 0.8833 - val_loss: 0.4203 - val_accuracy: 0.8589\n",
            "Epoch 866/900\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3044 - accuracy: 0.8827 - val_loss: 0.4234 - val_accuracy: 0.8531\n",
            "Epoch 867/900\n",
            "93/93 [==============================] - 3s 33ms/step - loss: 0.3046 - accuracy: 0.8803 - val_loss: 0.4220 - val_accuracy: 0.8555\n",
            "Epoch 868/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3038 - accuracy: 0.8816 - val_loss: 0.4197 - val_accuracy: 0.8531\n",
            "Epoch 869/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3070 - accuracy: 0.8803 - val_loss: 0.4153 - val_accuracy: 0.8571\n",
            "Epoch 870/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3019 - accuracy: 0.8825 - val_loss: 0.4177 - val_accuracy: 0.8531\n",
            "Epoch 871/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3065 - accuracy: 0.8805 - val_loss: 0.4138 - val_accuracy: 0.8558\n",
            "Epoch 872/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3035 - accuracy: 0.8806 - val_loss: 0.4298 - val_accuracy: 0.8516\n",
            "Epoch 873/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3085 - accuracy: 0.8790 - val_loss: 0.4134 - val_accuracy: 0.8552\n",
            "Epoch 874/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3027 - accuracy: 0.8829 - val_loss: 0.4186 - val_accuracy: 0.8539\n",
            "Epoch 875/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3028 - accuracy: 0.8816 - val_loss: 0.4148 - val_accuracy: 0.8584\n",
            "Epoch 876/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3054 - accuracy: 0.8815 - val_loss: 0.4121 - val_accuracy: 0.8551\n",
            "Epoch 877/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.2993 - accuracy: 0.8825 - val_loss: 0.4186 - val_accuracy: 0.8537\n",
            "Epoch 878/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3020 - accuracy: 0.8822 - val_loss: 0.4148 - val_accuracy: 0.8560\n",
            "Epoch 879/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3085 - accuracy: 0.8809 - val_loss: 0.4172 - val_accuracy: 0.8542\n",
            "Epoch 880/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.3023 - accuracy: 0.8814 - val_loss: 0.4156 - val_accuracy: 0.8558\n",
            "Epoch 881/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3044 - accuracy: 0.8802 - val_loss: 0.4177 - val_accuracy: 0.8528\n",
            "Epoch 882/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3021 - accuracy: 0.8828 - val_loss: 0.4159 - val_accuracy: 0.8553\n",
            "Epoch 883/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3015 - accuracy: 0.8829 - val_loss: 0.4211 - val_accuracy: 0.8537\n",
            "Epoch 884/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.2980 - accuracy: 0.8830 - val_loss: 0.4149 - val_accuracy: 0.8545\n",
            "Epoch 885/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3025 - accuracy: 0.8830 - val_loss: 0.4238 - val_accuracy: 0.8540\n",
            "Epoch 886/900\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3050 - accuracy: 0.8823 - val_loss: 0.4208 - val_accuracy: 0.8524\n",
            "Epoch 887/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3023 - accuracy: 0.8820 - val_loss: 0.4224 - val_accuracy: 0.8533\n",
            "Epoch 888/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.2999 - accuracy: 0.8836 - val_loss: 0.4193 - val_accuracy: 0.8545\n",
            "Epoch 889/900\n",
            "93/93 [==============================] - 3s 31ms/step - loss: 0.3024 - accuracy: 0.8825 - val_loss: 0.4204 - val_accuracy: 0.8543\n",
            "Epoch 890/900\n",
            "93/93 [==============================] - 4s 40ms/step - loss: 0.2975 - accuracy: 0.8827 - val_loss: 0.4187 - val_accuracy: 0.8549\n",
            "Epoch 891/900\n",
            "93/93 [==============================] - 4s 41ms/step - loss: 0.3005 - accuracy: 0.8831 - val_loss: 0.4198 - val_accuracy: 0.8545\n",
            "Epoch 892/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.2964 - accuracy: 0.8844 - val_loss: 0.4337 - val_accuracy: 0.8552\n",
            "Epoch 893/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3000 - accuracy: 0.8823 - val_loss: 0.4227 - val_accuracy: 0.8554\n",
            "Epoch 894/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3039 - accuracy: 0.8823 - val_loss: 0.4246 - val_accuracy: 0.8552\n",
            "Epoch 895/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3020 - accuracy: 0.8817 - val_loss: 0.4140 - val_accuracy: 0.8531\n",
            "Epoch 896/900\n",
            "93/93 [==============================] - 4s 38ms/step - loss: 0.3040 - accuracy: 0.8816 - val_loss: 0.4186 - val_accuracy: 0.8548\n",
            "Epoch 897/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3009 - accuracy: 0.8827 - val_loss: 0.4189 - val_accuracy: 0.8552\n",
            "Epoch 898/900\n",
            "93/93 [==============================] - 3s 32ms/step - loss: 0.3024 - accuracy: 0.8826 - val_loss: 0.4182 - val_accuracy: 0.8595\n",
            "Epoch 899/900\n",
            "93/93 [==============================] - 3s 35ms/step - loss: 0.3018 - accuracy: 0.8843 - val_loss: 0.4237 - val_accuracy: 0.8568\n",
            "Epoch 900/900\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.2971 - accuracy: 0.8853 - val_loss: 0.4233 - val_accuracy: 0.8551\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dc0b51f1810>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asMZfgGR9Js7",
        "outputId": "f3453590-a724-48e1-e5ec-88bb3fa28980"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1488/1488 [==============================] - 3s 2ms/step - loss: 0.1556 - accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15557649731636047, 0.9454175233840942]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_metric(model, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "OqYnWwcQOJDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3e5f4d-7e0d-467f-a0ed-a0e5664737f7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1488/1488 [==============================] - 3s 2ms/step\n",
            "263/263 [==============================] - 1s 2ms/step\n",
            "Test Set:\n",
            "[[2658   10  133]\n",
            " [  60 2511  230]\n",
            " [ 366  419 2016]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      2801\n",
            "           1       0.85      0.90      0.87      2801\n",
            "           2       0.85      0.72      0.78      2801\n",
            "\n",
            "    accuracy                           0.86      8403\n",
            "   macro avg       0.85      0.86      0.85      8403\n",
            "weighted avg       0.85      0.86      0.85      8403\n",
            "\n",
            "\n",
            "Train Set:\n",
            "[[15778     1    93]\n",
            " [   28 15569   275]\n",
            " [  829  1373 13670]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     15872\n",
            "           1       0.92      0.98      0.95     15872\n",
            "           2       0.97      0.86      0.91     15872\n",
            "\n",
            "    accuracy                           0.95     47616\n",
            "   macro avg       0.95      0.95      0.94     47616\n",
            "weighted avg       0.95      0.95      0.94     47616\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('scoring_model.h5')"
      ],
      "metadata": {
        "id": "pVl_UPLZLPky"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldIfKn4YL687"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}